[{"title":"mysql修改字符集","date":"2019-07-27T08:55:17.000Z","path":"2019/07/27/mysql/mysql修改字符集/","text":"概念 字符集（character set）：定义了字符以及字符的编码。 字符序（collation）：定义了字符的比较规则。 Mysql字符集 一个字符集对应至少一种字符序（一般是1对多）。 两个不同的字符集不能有相同的字符序。 每个字符集都有默认的字符序。 12345678910-- 第一种方式SHOW CHARACTER SET;-- 第二种方式use information_schema;select * from CHARACTER_SETS;-- 例子SHOW CHARACTER SET WHERE Charset=&quot;utf8&quot;;SHOW CHARACTER SET LIKE &quot;utf8%&quot;; Mysql字符序123456-- 第一种方式SHOW COLLATION WHERE Charset = &apos;utf8&apos;;-- 第二种方式USE information_schema;SELECT * FROM COLLATIONS WHERE CHARACTER_SET_NAME=&quot;utf8&quot;; 命名规范字符序的命名，以其对应的字符集作为前缀，如下所示。比如字符序utf8_general_ci，标明它是字符集utf8的字符序。 更多规则可以参考 官方文档。 1[information_schema]&gt; SELECT CHARACTER_SET_NAME, COLLATION_NAME FROM COLLATIONS WHERE CHARACTER_SET_NAME=&quot;utf8&quot; limit 2; 设置修改 修改数据库字符集 1234ALTER DATABASE db_name DEFAULT CHARACTER SET character_name [COLLATE ...];把表默认的字符集和所有字符列（CHAR,VARCHAR,TEXT）改为新的字符集：ALTER TABLE tbl_name CONVERT TO CHARACTER SET character_name [COLLATE ...]如：ALTER TABLE logtest CONVERT TO CHARACTER SET utf8 COLLATE utf8_general_ci; 修改表的默认字符集 12ALTER TABLE tbl_name DEFAULT CHARACTER SET character_name [COLLATE...];如：ALTER TABLE logtest DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; 修改字段的字符集 12ALTER TABLE tbl_name CHANGE c_name c_name CHARACTER SET character_name [COLLATE ...];如：ALTER TABLE logtest CHANGE title title VARCHAR(100) CHARACTER SET utf8 COLLATE utf8_general_ci; 查看数据库编码 1SHOW CREATE DATABASE db_name; 查看表编码 1SHOW CREATE TABLE tbl_name; 查看字段编码 1SHOW FULL COLUMNS FROM tbl_name; 查看系统的编码字符 1SHOW VARIABLES WHERE Variable_name LIKE &apos;character\\_set\\_%&apos; OR Variable_name LIKE &apos;collation%&apos;; MySQL字符集设置 系统变量： 12345678910111213– character_set_server：默认的内部操作字符集– character_set_client：客户端来源数据使用的字符集– character_set_connection：连接层字符集– character_set_results：查询结果字符集– character_set_database：当前选中数据库的默认字符集– character_set_system：系统元数据(字段名等)字符集– 还有以collation_开头的同上面对应的变量，用来描述字符序。 用introducer指定文本字符串的字符集： – 格式为：[_charset] ‘string’ [COLLATE collation] – 例如： 12345• SELECT _latin1 ‘string’;• SELECT _utf8 ‘你好’ COLLATE utf8_general_ci;–- 由introducer修饰的文本字符串在请求过程中不经过多余的转码，直接转换为内部字符集处理。 MySQL中的字符集转换过程 MySQL Server收到请求时将请求数据从character_set_client转换为character_set_connection； 进行内部操作前将请求数据从character_set_connection转换为内部操作字符集，其确定方法如下： • 使用每个数据字段的CHARACTER SET设定值； • 若上述值不存在，则使用对应数据表的DEFAULT CHARACTER SET设定值(MySQL扩展，非SQL标准)； • 若上述值不存在，则使用对应数据库的DEFAULT CHARACTER SET设定值； • 若上述值不存在，则使用character_set_server设定值。 参考 https://www.cnblogs.com/chyingp/p/mysql-character-set-collation.html https://www.cnblogs.com/qiumingcheng/p/10336170.html","tags":[{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"管理Odoo服务器实例","date":"2019-06-18T06:02:38.000Z","path":"2019/06/18/Odoo 12开发者指南第二章 管理Odoo服务器实例/","text":"全书完整目录请见：Odoo 12开发者指南（Cookbook）第三版 本章中，我们将讲解如下内容： 配置插件路径 更新插件模块列表 标准化你的实例目录布局 安装并升级本地插件模块 对插件应用修改 应用及尝试建议的拉取请求 引言在第一章 安装Odoo开发环境中，我们看了如何使用与编辑器一同发布的标准核心插件来设置 Odoo 实例。本章集中讲解为 Odoo 实例添加非核心插件。Odoo中，你可以从多个目录中加载插件。此外，推荐你将第三方插件（如OCA模块）或你自定义的插件放在一个单独的文件夹中，这样可以避免与 Odoo 核心模块产生冲突。甚至Odoo 企业版也是一种类型的插件目录，你需要像普通插件目录一样加载它。 ℹ️有关用词 – 插件(add-on) vs. 模块(module) 本书中，我们使用插件或插件模块来指代 Odoo 所预期安装的 Python 包。用户界面常使用应用（app）或模块的表达 ，但我们更愿意保留模块一词来表示Python模块或包，它们不一定是 Odoo 插件，而应用（app）来表示适当定义为应用的插件模块，表示它不是Odoo主菜单中的入口。 配置插件路径通过addons_path参数的配置，你可以在 Odoo 中加载自己的插件模块。在Odoo初始化一个新数据库时，它会搜索在addons_path配置参数中给定的这些目录。addons_path会在这些目录中搜索潜在的插件模块。addons_path中所列出的目录预期应包含子目录，每个子目录是一个插件模块。在数据库初始化完成后，你将能够安装这些目录中所给出的模块。 准备工作这一部分假定你已经准备好了实例并生成了配置文件，如在第一章 安装Odoo开发环境中在一个文件中存储实例配置一节所描述。Odoo的源码存放在~/odoo-dev/odoo中，而配置文件存放在~/odoo-dev/myinstance.cfg中。 如何配置…按如下步骤在实例的addons_path中添加~/odoo-dev/local-addons目录： 编辑你的实例的配置文件，即 ~/odoo-dev/my-instance.cfg。 定位到以addons_path =开头一行，默认，你会看到如下内容： 1addons_path = ~/odoo-dev/odoo/odoo/addons,~/odoo-dev/odoo/add-ons 译者注： 当前默认生成的配置文件中为绝对路径，且仅包含xxx/odoo/addons 修改该行，添加一个逗号（英文半角），并接你想想要添加为addons_的目录名称，如以下代码所示： 1addons_path = ~/odoo-dev/odoo/odoo/addons,~/odoo-dev/odoo/addons,~/odoo-dev/local-addons 重启你的实例 1$ ~/odoo-dev/odoo/odoo-bin -c my-instance.cfg 运行原理…在重启 Odoo 时，会读取配置文件。addons_path变量的值应为一个逗号分隔的目录列表。可接受相对路径，但它们是相对于当前工作目录的，因此应在配置文件中尽量避免。 至此，~/odoo-dev/local-addons中包含的新插件尚不在该实例的可用模块列表中。为此，你需要执行一个额外的操作，在下一部分更新插件模块列表中会进行讲解。 扩展知识…在第一次调用 odoo-bin脚本来初始化新数据库时，你可以传递一个带逗号分隔目录列表的–addons-path命令行参数。这会以所提供插件路径中所找到的所有插件来初始化可用插件模块列表。这么做时，你要显式地包含基础插件目录（odoo/odoo/addons）以及核心插件目录（odoo/addons）。 与前面稍有不同的是本地插件目录不能为空（译者注：请先阅读下面的小贴士），它必须要至少包含一个子目录，并包含插件模块的最小化结构。在第四章 创建Odoo插件模块中，我们会来看如何编写你自己的模块。同时，这里有一个生成内容来满足Odoo要求的快捷版黑科技： 1$ mkdir -p ~/odoo-dev/local-addons/dummy$ touch ~/odoo-dev/local-addons/dummy/__init__.py$ echo &apos;&#123;&quot;name&quot;: &quot;dummy&quot;, &quot;installable&quot;: False&#125;&apos; &gt; \\~/odoo-dev/local-addons/dummy/__manifest__.py 你可以使用–save选项来保存配置文件的路径： 1$ odoo/odoo-bin -d mydatabase \\--add-ons-path=&quot;odoo/odoo/addons,odoo/addons,~/odoo-dev/local-addons&quot; \\--save -c ~/odoo-dev/my-instance.cfg --stop-after-init 本例中，使用相对路径不会有问题，因为它们会在配置文件中转化为绝对路径。 小贴士：因为Odoo仅当从命令行中设置路径时在插件路径的目录中查看插件，而不是在从配置文件中加载路径的时候，dummy已不再必要。因此，你可以删除它（或保留到你确定不需要新建一个配置文件时）。 更新插件模块列表我们在前面的部分已经说到，在向插件路径添加目录时，仅仅重启Odoo服务是不足以安装其中一个新插件模块的。Odoo还需要有一个指定动作来扫描路径并更新可用插件模块的列表。 准备工作启动你的实例并使用管理员账号连接它。然后，激活开发者模式（如果你不知道如何激活开发者模式，请参见第一章 安装Odoo开发环境）。 如何更新…要更新你实例中的可用插件模块列表，你需要执行如下步骤： 打开Apps菜单 点击Update Apps List：[ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050902052063.jpg) 在弹出对话框中，点击Update按钮：[ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050902070776.jpg) 在更新的最后，你可以点击Apps入口来查看已更新的可用插件模块列表。你将需要删除Apps搜索框中的默认过滤器来查看所有模块。 运行原理…在点击了Update按钮之后，Odoo会读取插件路径配置变量。对于列表中的每一个目录，它会查看包含保存在插件模块目录中名为manifest.py的插件声明文件的直接子目录。Odoo读取声明内容，并预期查找其中的Python字典。除非声明内容中包含一个键installable的值为False，插件模块的元数据就会存储在数据库中。如果模块已存在，则更新相关信息。否则，会创建一条新记录。如果此前可用的插件模块未找到，则从列表中删除该记录。 ℹ️仅在初始化数据库后添加了新的插件路径时才需要更新应用列表。如果你在初始化数据库之前在配置文件中添加了新插件路径，那么就无需手动更新模块列表。 标准化你的实例目录布局我们推荐你在开发和生产环境都使用相似的目录布局。这一标准化会在你要执行运维时体现出用处，它也会缓解你日常工作的压力。 这一部分创建将相似生命周期或相似用途的文件分组放在标准化子目录中的目录结构。请自由按照自己的需求来调整这一结构，但请确保你将这一结构在某处进行记录存档。 如何标准化…创建所推荐实例布局，你需要执行如下步骤： 译者注：读者也可直接使用 Alan 在 GitHub 上准备的安装脚本进行操作 为实例创建一个目录： 1$ mkdir ~/odoo-dev/projectname$ cd ~/odoo-dev/projectname 在名为env/的子目录中创建一个Python虚拟环境： 1$ virtualenv -p python3 env 创建一些子目录，如下： 1$ mkdir src local bin filestore logs 这些子目录的功能如下： src/：这包含Odoo本身的一个拷贝，以及一些第三方插件项目（我们在下一步中添加了Odoo源码） local/：这用于保存你针对具体实例的插件 bin/：这包含各类帮助可执行shell脚本 filestore/：这用于文件存储 logs/（可选）：这用于存储服务日志文件 克隆Odoo并安装所需依赖包（参见 第一章 安装Odoo开发环境 获取更多内容）： 12$ git clone https://github.com/odoo/odoo.git src/odoo$ env/bin/pip3 install -r src/odoo/requirements.txt 以bin/odoo保存如下shell脚本： 12345ROOT=$(dirname $0)/..PYTHON=$ROOT/env/bin/python3ODOO=$ROOT/src/odoo/odoo-bin$PYTHON $ODOO -c $ROOT/projectname.cfg \"$@\"exit $? 让该脚本可执行： 1$ chmod +x bin/odoo 创建一个空的本地模块dummy： 123$ mkdir -p local/dummy$ touch local/dummy/__init__.py$ echo &apos;&#123;&quot;name&quot;: &quot;dummy&quot;, &quot;installable&quot;: False&#125;&apos; &gt;\\local/dummy/__manifest__.py 为你的实例生成配置文件： 1$ bin/odoo --stop-after-init --save \\ --addons-path src/odoo/odoo/addons,src/odoo/addons,local \\ --data-dir filestore 添加一个.gitignore文件，用于告诉GitHub排除这些给定目录，这样Git在提交代码时就会忽略掉这些目录，例如 filestore/, env/, logs/和src/： 123456789101112# dotfiles, with exceptions:.*!.gitignore# python compiled files*.py[co]# emacs backup files*~# not tracked subdirectories/env//src//filestore//logs/ 为这个实例创建一个Git仓库并将已添加的文件添加到Git中： 123$ git init$ git add .$ git commit -m \"initial version of projectname\" 运行原理…我们生成了一个有明确标签目录和独立角色的干净的目录结构。我使用了不同的目录来存储如下内容： 由其它人所维护的代码（src/中） 本地相关的具体代码 实例的文件存储 通过为每个项目建一个virtualenv环境，我们可以确保该项目的依赖文件不会与其它项目的依赖产生冲突，这些项目你可能运行着不同的Odoo版本或使用了不同的第三方插件模块，这将需要不同版本的Python依赖。这当然也会带来一部分磁盘空间的开销。 以类似的方式，通过为我们不同的项目使用不同的Odoo拷贝以及第三方插件模块，我们可以让每个项目单独的进行推进并仅在需要时在这些实例上安装更新，因此也减少了引入回退的风险。 bin/odoo允许我们不用记住各个路径或激活虚拟环境就可以运行服务。这还为我们设置了配置文件。你可以在其中添加其它脚本来协助你的日常工作。例如，你可以添加一个脚本来检查运行实例所需的第三方项目。 有关配置文件，我们仅展示了这里需要设置的最小化选项，但很明显你可以设置更多，例如数据库名、数据库过滤器或项目所监听的端口。有关这一话题的更多信息，请参见第一章 安装Odoo开发环境。 最后，通过在Git仓库中管理所有这些，在不同的电脑上复制这一设置及在团队中分享开发内容变得相当容易。 小贴士：加速贴士 要加速项目的创建，你可以创建一个包含空结构的模板仓库，并为每个项目复制（fork）该仓库。这会省却你重新输入bin/odoo脚本、.gitignore及其它所需模板文件（持续集成配置、README.md、ChangeLog等等）所花费的时间。 参见内容如果你喜欢这种方法，我们建议你尝试第三章 服务器部署中的使用 Docker 运行 Odoo 一部分的内容。 扩展知识…复杂模块的开发要求有各类配置选项，在想要尝试任何配置选项时都会要更新配置文件。更新配置常常是一件头痛的事，避免它的一种方式是通过命令行传递所有配置选项，如下： 手动激活虚拟环境： 1$ source env/bin/activate 进行Odoo源代码目录： 1$ cd src/odoo 运行服务： 1./odoo-bin --addons-path=addons,../../local -d test-12 -i account,sale,purchase --log-level=debug 第三步中，我们直接通过命令行传递了一些参数。第一个是–addons-path，它加载Odoo的核心插件目录addons，以及你自己的插件目录local，在其中你可以放自己的插件模块。选项-d会使用test-12数据库或者在该数据库不存在时新建一个数据库。选项-i 会安装会计、销售和采购模块。接着，我们传递了log-level选项来将日志级别提升为debug，这样日志中会显示更多的信息。 ℹ️通过使用命令行，你可以快速地修改配置选项。你也可以在Terminal中查看实时日志。所有可用选项可参见第一章 安装Odoo开发环境，或使用-help命令来查看所有的选项列表及各个选项的描述。 安装并升级本地插件模块Odoo 功能的核心来自于它的插件模块。Odoo自带的插件是你所拥有的财富，同时你也可以在应用商店下载一些插件模块或者自己写。 这一部分中，我们将展示如何通过网页界面及命令行来安装并升级插件模块。 对这些操作使用命令行的主要好处包含可以同时作用于一个以上的插件以及在安装或升级的过程中可以清晰地浏览到服务端日志，对于开发模式或编写脚本安装实例时都非常有用。 准备工作确保你有一个运行中的 Odoo 实例，且数据库已初始化、插件路径已进行恰当地设置。在这一部分中，我们将安装/升级一些插件模块。 如何安装升级…安装或升级插件有两种方法-可以使用网页界面或命令行。 通过网页界面可按照如下步骤来使用网页界面安装新的插件模块到数据库中： 使用管理员账户连接实例并打开Apps菜单[ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050906002399.jpg) 使用搜索框来定位你想要安装的插件。这里有一些帮助你完成该任务的操作指南： 激活Not Installed过滤器 如果你要查找一个具体的功能插件而不是广泛的功能插件，删除Apps过滤器 在搜索框中输入模块名的一部分并使用它来作为模块过滤器 你会发现使用列表视图可以阅读到更多的信息 点击卡片中模块名下的Install按钮。 注意有些Odoo插件模块需要有外部Python依赖，如果你的系统中未安装该Python依赖，那么 Odoo 会中止安装并显示如下的对话框： [ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050906125210.jpg) 译者注：按正常安装不会出现一错误，需通过 pip uninstall pyldap 才能复现这一错误 修复这一问题，仅需在你的系统中安装相关的Python依赖即可。 要升级已安装到数据库的模块，使用如下步骤： 使用管理员账户连接到实例 打开Apps菜单 点击Apps:[ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050906203077.jpg) 使用搜索框来定位你所安装的插件。有如下的小贴士： 激活Installed过滤器 如果你要查找一个具体的功能插件而不是广泛的功能插件，删除Apps过滤器 在搜索框中输入部分插件模块的名称并按下 Enter 来使用它作为模块过滤器。例如，输入CRM并按下 Enter 来搜索CRM应用 你会发现使用列表视图可以阅读到更多的信息 点击卡片右上角的的三个点，然后点击Upgrade选项： [ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050906265357.jpg) 激活开发者模式来查看模块的技术名称。如果你不知道如何激活开发者模式，请参见第一章 安装Odoo开发环境： [ Odoo 12开发者指南第二章 管理Odoo服务器实例](https://alanhou.org/homepage/wp-content/uploads/2019/05/2019050906302261.jpg) 在激活开发者模式之后，它会以红色显示模块的技术名称。如果你使用的是Odoo社区版，会看到一些带有Upgrade的附加应用。这些是Odoo企业版的应用，要想安装/使用它们，需要购买一个证书。 通过命令行要在你的数据库中安装新插件，可按照如下步骤： 查找插件的名称。这是包含manifest.py文件的目录名，不带前面的路径。 停止实例。如果你在操作生产数据库，请进行备份。 运行如下命令： 1odoo/odoo-bin -c instance.cfg -d dbname -i addon1,addon2 --stop-after-init 译者注： 请将addon1,addon2替换为你所要安装的插件名 小贴士：你可以省略掉-d dbname，因为这在配置文件中进行了设置。 重新启动实例 运行原理…插件模块的安装和升级是两个紧密关联的操作，但有一些重要的区别，在下面两部分中进行了强调： 插件安装在你安装插件时，Odoo以提供的名称检查它的可用插件列表中未安装插件。它还会检查该插件的依赖，并且如果有依赖的话，它会在安装插件前递归安装这些依赖。 单个模块的安装包含如下步骤： 如果存在，运行插件preinit钩子 从Python源代码中加载模型定义并在必要时更新数据库结构（参见第五章 应用模型了解更多信息） 加载插件的数据文件并在必要时更新数据库内容（参见第七章 模块数据了解更多信息） 如果实例中启用了演示数据则安装插件演示数据 如果存在，运行插件postinit钩子 运行对插件视图定义的验证 如果启用了演示数据并启用了测试，运行该插件的测试（参见第十八章 自动化测试用例了解更多信息） 在数据库中更新模块状态 从插件的翻译文件中更新数据库中的翻译（参见第十二章 国际化了解更多信息） ℹ️preinit和postinit钩子分别使用pre_init_hook和post_init_hook键名在manifest.py文件中定义。这些钩子用于在插件模块的安装之前及之后触发Python函数。参见第四章 创建Odoo插件模块了解更多有关 init 钩子的知识。 插件升级升级插件时，Odoo以给定的名称在可用的插件模块列表中检查已安装插件。它还会检查该插件的反向依赖（即依赖于所升级插件的那些插件）。如果存在，则也会对它们进行递归升级。 单个插件模块的升级过程包含如下步骤： 如果有的话，先运行插件模块的预迁移步骤（参见第七章 模块数据了解更多信息） 从Python源码中加载模型定义并在必要时更新数据库结构（参见第五章 应用模型了解更多信息） 加载插件的数据文件并在必要时更新数据库内容（参见第七章 模块数据了解更多信息） 如果实例中启用了演示数据更新插件演示数据 如果模块有任何迁移方法的话，先运行插件模块的后置迁移步骤（参见第七章 模块数据了解更多信息） 运行对插件视图定义的验证 如果启用了演示数据并启用了测试，运行该插件的测试（参见第十八章 自动化测试用例了解更多信息） 在数据库中更新模块状态 从插件的翻译文件中更新数据库中的翻译（参见第十二章 国际化了解更多信息） ℹ️注意更新未安装的插件模块什么也不会做。但是安装已安装的插件模块会重新安装该插件，这会通过一些包含数据的数据文件产生一些预期外的问题，这些文件可能应由用户进行更新而非在常规的模块升级处理时进行更新（参见第七章 模块数据中使用noupdate和forcecreate标记部分的内容）。通过用户界面不存在错误的风险，但通过命令行时则有可能发生。 扩展知识…要当心依赖的处理。假定有一个实例你想要安装sale、sale_stock和sale_specific插件，sale_specific依赖于sale_stock，而sale_stock依赖于sale。要安装这三者，你只需要安装sale_specific，因为它会递归安装sale_stock和sale这两个依赖。要升级这两者，你需要升级sale，因为这样会递归升级其反向依赖，sale_stock和sale_specific。 管理依赖另一个比较搞的地方是在你向已经有一个版本安装了的插件添加依赖的时候。我们继续通过前例来理解这一问题。想像一下你在sale_specific中添加了一个对stock_dropshipping的依赖。更新sale_specific插件不会自动安装新的依赖，也会要求安装sale_specific。在这种情况下，你会收到非常糟糕的错误消息，因为插件的Python代码没有成功的加载，而插件的数据和模型表则存在于数据库中。要解决这一问题，你需要停止该实例并手动安装新的依赖。 从GitHub安装插件模块GitHub是第三方插件的一个很好的来源。很多Odoo合作伙伴使用GitHub来分享他们内部维护的插件，而Odoo社区联盟（OCA）在GitHub上共同维护着几百个插件。在你开始编写自己的插件之前，确保查看是否已有可用的插件或者作为初始以继续扩展插件。 这一部分向你展示如何从GitHub上克隆OCA的partner-contact项目并让其中所包含的插件模块在我们实例中可用。 准备工作假设你想要改变你的实例中地址的处理方式，你的客户需要在Odoo两个字段（街道和街道2）之外的第三个字段来存储地址。你肯定是可以编写自己的插件来为res.partne添加一个字段的，但如果想要让地址在发票上以合适的格式显示，问题就要比看上去麻烦一些了。所幸，你邮件列表上的某个人告诉了你partner_address_street3插件，由OCA作为partner-contact项目的一部分进行维护。 本部分中所使用的路径反映了我们在标准化你的实例目录布局一节中所推荐的布局。 如何安装…按照如下步骤来安装partner_address_street3： 进入你的项目目录： 1$ cd ~/odoo-dev/my-odoo/src 在src/目录中克隆partner-contact项目的12.0分支： 1$ git clone --branch 12.0 \\https://github.com/OCA/partner-contact.git src/partner-contact 修改插件路径来包含该目录并更新你的实例中的插件列表（参见本章中的配置插件路径和更新插件模块列表一节）。instance.cfg中的addons_path一行应该是这样的： 1addons_path = ~/odoo-dev/my-odoo/src/odoo/odoo/addons, \\~/odoo-dev/my-odoo/src/odoo/addons, \\~/odoo-dev/my-odoo/src/, \\~/odoo-dev/local-addons 安装partner_address_street3插件（如果你不知道如何安装该模块，参见前面一节，安装并升级本地插件模块） 运行原理…所有 Odoo社区联盟的代码仓库都将他们自己的插件放在单独的目录中，这与Odoo对插件路径中目录的预期是相一致的。因此，只需复制某处的仓库并将其添加到插件路径中就够了。 扩展知识…有些维护者遵循不同的方法，每个插件模块一个仓库，放在仓库的根目录下。这种情况下，你需要创建一个新的目录，在这个目录中添加插件路径并克隆你所需的维护者的插件到该目录中。记住在每次添加一个新仓库拷贝时要更新插件模块列表。 对插件应用修改GitHub上可用的大部分插件需要进行修改并且不遵循Odoo对其稳定发行版所强制的规则。它们可能收到漏洞修复或改善，包含你提交的问题或功能请求，这些修改可能会引入数据库模式的修改或数据文件和视图中的更新。这一部分讲解如何安装升级后的版本。 准备工作假定你对partner_address_street3报告了一个问题并收到通知说该问题已在partner-contact项目12.0分支的最近一次修订中得以解决。这种情况下，你可以使用最新版本来更新你的实例。 如何修改…要对GitHub的插件进行源的变更，需执行如下步骤： 停止使用该插件的实例。 如果是生产实例请做一个备份（参见第一章 安装Odoo开发环境中管理Odoo服务端数据库一节）。 进入克隆了partner-contact的目录： 1$ cd ~/odoo-dev/my-odoo/src/partner-contact 为该项目创建一个本地标签，这样万一出现了崩溃你可以进行回退： 1$ git checkout 12.0$ git tag 12.0-before-update-$(date --iso) 获取源码的最新版本： 1$ git pull --ff-only 在你的数据库中更新partner_address_street3插件（参见安装并升级本地插件模块一节） 重启实例 运行原理…通常，插件模块的开发者有时会发布插件的最新版本。这一更新一般包含漏洞修复及新功能。这里，我们将获取一个插件的新版本并在我们的实例中更新它。 如果git pull –ff-only失败的话，你可以使用如下命令回退到前一个版本： 1$ git reset --hard 12.0-before-update-$(date --iso) 然后，你可以尝试git pull（不添加–ff-only），它会产生一个合并，但这表示你对插件做了本地修改。 扩展知识…如果更新这一步崩溃了，参见第一章 安装Odoo开发环境从源码更新Odoo一节获取恢复的操作指南。记住要总是在一个生产数据库的拷贝上先进行测试。 应用及尝试建议的拉取请求在GitHub的世界中，拉取请求（PR）是由开发者所提交的请求，这样项目维护人员可以添加一些新的开发。比如一个 PR 可能包含漏洞修复或新功能。这里请求在拉取到主分支之前会进行审核和测试。 这一部分讲解如何对你的 Odoo 项目应用一个PR来测试漏洞修复的改进。 准备工作在前一节中，假定你对partner_address_street3 报告了一个问题并收到一条通知在拉取请求中问题已修复，尚未合并到项目的12.0分支中。开发人员要求你验证PR #123中的修复状况。你需要使用这一分支更新一个测试实例。 你不应在生产数据库直接使用该分支，因此先创建一个带有生产数据库拷贝的测试环境（参见第一章 安装Odoo开发环境和第三章 服务器部署）。 如何操作…应用并测试一个插件的GitHub拉取请求，你需要执行如下步骤： 停止实例 进入partner-contact所被克隆的目录： 1$ cd ~/odoo-dev/my-odoo/src/partner-contact 为该项目创建一个本地标签，这样万一出现崩溃时你可以回退： 1$ git checkout 12.0$ git tag 12.0-before-update-$(date --iso 拉取pull请求的分支。这么做最容易的方式是使用PR编号，在开发者与你沟通时你应该可以看到。在本例中，这个拉取请求编号是123： 1$ git pull origin pull/123/head 在你的数据库中更新partner_address_street3插件模块并重启该实例（如果你不知道如何更新该模块的话请参见安装并升级本地插件模块一节） 测试该更新 – 尝试重现问题，或测试你想要的功能。 如果这不能运行，在GitHub的PR页面进行评论，说明你做了什么以及什么不能运行，这样开发者可以更新这个拉取请求。 如果它没有问题，也在PR页面说下；这是PR验证流程中非常重要的一部分；这会加速主分支中的合并。 运行原理…我们在使用一个GitHub功能，使用pull/nnnn/head分支名称来通过编号进行拉取请求的拉取，其中nnnn是PR的编号。Git pull命令合并远程分支到我们的分支，在我们基础代码中应用修改。在这之后，我们更新插件模块、对其测试并向作者报回修改是成功或是失败。 扩展知识…如果你想要同步测试它们，你可以针对相同仓库的不同拉取请求重复本节中的第4步。如果你对结果很满意，你可以创建一个分支来保留对应用了改变的结果的引用： 1$ git checkout -b 12.0-custom 使用一个不同的分支会帮助你记住你没有从GitHub使用该版本，而是一个自定义的版本。 ℹ️git branch命令可用于列出你仓库中的所有本地分支。 从这开始，如果你需要应用来自GitHub中12.0分支的最近一个审核版本，你需要不使用–ff-only来拉取它： 1$ git pull origin 12.0","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"},{"name":"odoo","slug":"odoo","permalink":"http://wumuwumu.github.io/tags/odoo/"}]},{"title":"__import__在python中的区别","date":"2019-06-01T07:49:16.000Z","path":"2019/06/01/import-在python中的区别/","text":"import作用：导入/引入一个python标准模块，其中包括.py文件、带有init.py文件的目录(自定义模块)。 import module_name[,module1,…] from module import *|child[,child1,…] 注意：多次重复使用import语句时，不会重新加载被指定的模块，只是把对该模块的内存地址给引用到本地变量环境。 实例： pythontab.py 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `os ``print` `'in pythontab'``,``id``(os)` test.py 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `pythontab ``#第一次会打印pythontab里面的语句 ``import` `os ``#再次导入os后，其内存地址和pythontab里面的是一样的，因此这里只是对os的本地引用 ``print` `&apos;in c&apos;``,``id``(os) ``import` `pythontab ``#第二次不会打印pythontab里面的语句，因为没有重新加载` reload作用：对已经加载的模块进行重新加载，一般用于原模块有变化等特殊情况，reload前该模块必须已经import过。 import os reload(os) 说明： reload会重新加载已加载的模块，但原来已经使用的实例还是会使用旧的模块，而新生产的实例会使用新的模块；reload后还是用原来的内存地址；不能支持from。。import。。格式的模块进行重新加载。 实例： pythontab.py 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `os ``print` `'in pythontab'``,``id``(os)` test.py 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `pythontab ``#第一次import会打印pythontab里面的语句 ``print` `id``(pythontab) ``#原来pythontab的内存地址 ``reload``(pythontab) ``#第二次reload还会打印pythontab里面的语句，因为有重新加载 ``print` `id``(pythontab) ``#reload后pythontab的内存地址，和原来一样` 扩展： 上面说了，在特殊情况的下才会使用reload函数；除了原来模块文件有修改外，还有哪些情况需要使用reload函数呢，这里举个例子。 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``#引用sys模块进来，并不是进行sys的第一次加载 ``reload``(sys) ``#重新加载sys ``sys.setdefaultencoding(``'utf8'``) ``##调用setdefaultencoding函数` 上面的代码是正确的，再测试下面的代码 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``sys.setdefaultencoding(``'utf8'``)` 上面的测试会失败，那么为什么要在调用setdefaultencoding时必须要先reload一次sys模块呢？因为这里的import语句其实并不是sys的第一次导入语句，也就是说这里其实可能是第二、三次进行sys模块的import，这里只是一个对sys的引用，只能reload才能进行重新加载；那么为什么要重新加载，而直接引用过来则不能调用该函数呢？因为setdefaultencoding函数在被系统调用后被删除了，所以通过import引用进来时其实已经没有了，所以必须reload一次sys模块，这样setdefaultencoding才会为可用，才能在代码里修改解释器当前的字符编码。试试下面的代码，同样会报错： 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``reload``(sys) ``sys.setdefaultencoding(``'utf8'``) ``del` `sys.setdefaultencoding ``##删除原来的setdefaultencoding函数 ``sys.setdefaultencoding(``'gb2312'``)` 那么到底是谁在之前就导入sys并且调用了setdefaultencoding函数呢？答案就在python安装目录的Lib文件夹下，有一个叫site.py的文件【python2.6】，在里面可以找到main() –&gt; setencoding()–&gt;sys.setdefaultencoding(encoding),因为这个site.py每次启动python解释器时会自动加载，所以main函数每次都会被执行，setdefaultencoding函数一出来就已经被删除了。 import作用： 同import语句同样的功能，但import是一个函数，并且只接收字符串作为参数，所以它的作用就可想而知了。其实import语句就是调用这个函数进行导入工作的，import sys &lt;==&gt;sys = import(‘sys’) 使用： import(module_name[, globals[, locals[, fromlist]]]) #可选参数默认为globals(),locals(),[] import(‘os’) import(‘os’,globals(),locals(),[‘path’,’pip’]) #等价于from os import path, pip 说明： 通常在动态加载时可以使用到这个函数，比如你希望加载某个文件夹下的所用模块，但是其下的模块名称又会经常变化时，就可以使用这个函数动态加载所有模块了，最常见的场景就是插件功能的支持。 扩展： 既然可以通过字符串来动态导入模块，那么是否可以通过字符串动态重新加载模块吗？试试reload(‘os’)直接报错，是不是没有其他方式呢?虽然不能直接reload但是可以先unimport一个模块，然后再import来重新加载模块。现在看看unimport操作如何实现，在Python解释里可以通过globals(),locals(),vars(),dir()等函数查看到当前环境下加载的模块及其位置，但是这些都只能看不能删除，所以无法unimport；不过除此之外还有一个地方是专门存放模块的，这就是sys.modules，通过sys.modules可以查看所有的已加载并且成功的模块，而且比globals要多，说明默认会加载一些额外的模块，接下来就是unimport了。 1`#!/usr/bin/env python ``#encoding: utf-8 ``import` `sys ``__import__``(``'a'``) ``#第一次导入会打印消息 ``del` `sys.modules[``'a'``] ``#unimport ``__import__``(``'a'``) ``#再次导入还是会打印消息，因为已经unimport一次了 ``__import__``(``'a'``) ``#这次就不会打印消息了`","tags":[{"name":"python","slug":"python","permalink":"http://wumuwumu.github.io/tags/python/"}]},{"title":"java多线程自问","date":"2019-04-15T02:31:35.000Z","path":"2019/04/15/java多线程自问/","text":"java创建线程的方式 java的线程的类型 Timer与TimerTask的区别 怎么启动、停止、加入、礼让线程 线程的生命周期以及其切换 CountDownLatch、CyclicBarrier和Semaphore 什么是线程安全？Vector是一个线程安全类吗？","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"redis分布式锁","date":"2019-04-11T09:55:56.000Z","path":"2019/04/11/redis分布式锁/","text":"单机Redis实现分布式锁获取锁获取锁的过程很简单，客户端向Redis发送命令： 12SET resource_name my_random_value NX PX 30000复制代码 my_random_value是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。 NX表示只有当resource_name对应的key值不存在的时候才能SET成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。 PX 30000表示这个锁有一个30秒的自动过期时间。 释放锁123456if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end复制代码 之前获取锁的时候生成的my_random_value 作为参数传到Lua脚本里面，作为：ARGV[1],而 resource_name作为KEYS[1]。Lua脚本可以保证操作的原子性。 关于单点Redis实现分布式锁的讨论网络上有文章说用如下命令获取锁: 123SETNX resource_name my_random_valueEXPIRE resource_name 30复制代码 由于这两个命令不是原子的。如果客户端在执行完SETNX后crash了，那么就没有机会执行EXPIRE了，导致它一直持有这个锁，其他的客户端就永远获取不到这个锁了。 为什么my_random_value 要设置成随机值? 保证了一个客户端释放的锁是自己持有的那个锁。如若不然，可能出现锁不安全的情况。 123456客户端1获取锁成功。客户端1在某个操作上阻塞了很长时间。过期时间到了，锁自动释放了。客户端2获取到了对应同一个资源的锁。客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。复制代码 用 SETNX获取锁 网上大量文章说用如下命令获取锁： 12SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt;复制代码 原文在Redis对SETNX的官网说明，Redis官网文档建议用Set命令来代替，主要原因是SETNX不支持超时时间的设置。 redis.io/commands/se… Redis集群实现分布式锁上面的讨论中我们有一个非常重要的假设：Redis是单点的。如果Redis是集群模式，我们考虑如下场景: 123456客户端1从Master获取了锁。Master宕机了，存储锁的key还没有来得及同步到Slave上。Slave升级为Master。客户端2从新的Master获取到了对应同一个资源的锁。客户端1和客户端2同时持有了同一个资源的锁，锁不再具有安全性。复制代码 就此问题，Redis作者antirez写了RedLock算法来解决这种问题。 RedLock获取锁 获取当前时间。 按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。 计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。 如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。 如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的单机Redis Lua脚本释放锁的方法）。 RedLock释放锁客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。 关于RedLock的问题讨论 如果有节点发生崩溃重启 假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列： 12345客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。节点C重启后，客户端2锁住了C, D, E，获取锁成功。客户端1和客户端2同时获得了锁。复制代码 为了应对这一问题，antirez又提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。 如果客户端长期阻塞导致锁过期 解释一下这个时序图，客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。 如何解决这个问题呢?引入了fencing token的概念： 客户端1先获取到的锁，因此有一个较小的fencing token，等于33，而客户端2后获取到的锁，有一个较大的fencing token，等于34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次33的请求。这样就避免了冲突。 但是其实这已经超出了Redis实现分布式锁的范围，单纯用Redis没有命令来实现生成Token。 时钟跳跃问题 假设有5个Redis节点A, B, C, D, E。 123456客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。客户端1和客户端2现在都认为自己持有了锁。这个问题用Redis实现分布式锁暂时无解。而生产环境这种情况是存在的。复制代码 结论 Redis并不能实现严格意义上的分布式锁。但是这并不意味着上面讨论的方案一无是处。如果你的应用场景为了效率(efficiency)，协调各个客户端避免做重复的工作，即使锁失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。但是如果你的应用场景是为了正确性(correctness)，那么用Redis实现分布式锁并不合适，会存在各种各样的问题，且解决起来就很复杂，为了正确性，需要使用zab、raft共识算法，或者使用带有事务的数据库来实现严格意义上的分布式锁。 参考资料 Distributed locks with Redis 基于Redis的分布式锁到底安全吗（上）？ - 铁蕾的个人博客 martin.kleppmann.com/2016/02/08/…","tags":[{"name":"redis","slug":"redis","permalink":"http://wumuwumu.github.io/tags/redis/"}]},{"title":"","date":"2019-04-10T02:32:39.000Z","path":"2019/04/10/java-线程池/","text":"title: java-线程池date: 2019-04-10 10:32:39tags: java 1. 线程池的关系ExecutorService1234![1536473588949](assets/1536473588949.png)## 2. ```Executor public interface Executor { void execute(Runnable command);}12## 3. javapublic abstract class AbstractExecutorService implements ExecutorService { // RunnableFuture 是用于获取执行结果的，我们常用它的子类 FutureTask // 下面两个 newTaskFor 方法用于将我们的任务包装成 FutureTask 提交到线程池中执行 protected RunnableFuture newTaskFor(Runnable runnable, T value) { return new FutureTask(runnable, value); } protected RunnableFuture newTaskFor(Callable callable) { return new FutureTask(callable); } // 提交任务 public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture ftask = newTaskFor(task, null); execute(ftask); return ftask; } /* @throws RejectedExecutionException {@inheritDoc} @throws NullPointerException {@inheritDoc} / public Future submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); // 1. 将任务包装成 FutureTask RunnableFuture ftask = newTaskFor(task, result); // 2. 交给执行器执行，execute 方法由具体的子类来实现 // 前面也说了，FutureTask 间接实现了Runnable 接口。 execute(ftask); return ftask; } public Future submit(Callable task) { if (task == null) throw new NullPointerException(); RunnableFuture ftask = newTaskFor(task); execute(ftask); return ftask; } // 此方法目的：将 tasks 集合中的任务提交到线程池执行，任意一个线程执行完后就可以结束了 // 第二个参数 timed 代表是否设置超时机制，超时时间为第三个参数， // 如果 timed 为 true，同时超时了还没有一个线程返回结果，那么抛出 TimeoutException 异常 private T doInvokeAny(Collection&lt;? extends Callable&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); ArrayList&lt;Future&gt; futures = new ArrayList&lt;Future&gt;(ntasks); // ExecutorCompletionService 不是一个真正的执行器，参数 this 才是真正的执行器 // 它对执行器进行了包装，每个任务结束后，将结果保存到内部的一个 completionQueue 队列中 // 这也是为什么这个类的名字里面有个 Completion 的原因吧。 ExecutorCompletionService ecs = new ExecutorCompletionService(this); // For efficiency, especially in executors with limited // parallelism, check to see if previously submitted tasks are // done before submitting more of them. This interleaving // plus the exception mechanics account for messiness of main // loop. try { // 用于保存异常信息，此方法如果没有得到任何有效的结果，那么我们可以抛出最后得到的一个异常 ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&gt; it = tasks.iterator(); // 首先先提交一个任务，后面的任务到下面的 for 循环一个个提交 futures.add(ecs.submit(it.next())); –ntasks; int active = 1; for (;;) { // ecs 上面说了，其内部有一个 completionQueue 用于保存执行完成的结果 // BlockingQueue 的 poll 方法不阻塞，返回 null 代表队列为空 Future f = ecs.poll(); // 为 null，说明刚刚提交的第一个线程还没有执行完成 // 在前面先提交一个任务，加上这里做一次检查，也是为了提高性能 if (f == null) { if (ntasks &gt; 0) { –ntasks; futures.add(ecs.submit(it.next())); ++active; } // 这里是 else if，不是 if。这里说明，没有任务了，同时 active 为 0 说明 // 任务都执行完成了。其实我也没理解为什么这里做一次 break？ // 因为我认为 active 为 0 的情况，必然从下面的 f.get() 返回了 else if (active == 0) break; // 这里也是 else if。这里说的是，没有任务了，但是设置了超时时间，这里检测是否超时 else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); } else // else。说明，没有任务需要提交，但是池中的任务没有完成，还没有超时(如果设置了超时) // take() 方法会阻塞，直到有元素返回，说明有任务结束了 f = ecs.take(); } // 有任务结束了 if (f != null) { –active; try { // 返回执行结果，如果有异常，都包装成 ExecutionException return f.get(); } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } public T invokeAny(Collection&lt;? extends Callable&gt; tasks) throws InterruptedException, ExecutionException { try { return doInvokeAny(tasks, false, 0); } catch (TimeoutException cannotHappen) { assert false; return null; } } public T invokeAny(Collection&lt;? extends Callable&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return doInvokeAny(tasks, true, unit.toNanos(timeout)); } // 执行所有的任务，返回任务结果。 // 先不要看这个方法，我们先想想，其实我们自己提交任务到线程池，也是想要线程池执行所有的任务 // 只不过，我们是每次 submit 一个任务，这里以一个集合作为参数提交 public List&lt;Future&gt; invokeAll(Collection&lt;? extends Callable&gt; tasks) throws InterruptedException { if (tasks == null) throw new NullPointerException(); ArrayList&lt;Future&gt; futures = new ArrayList&lt;Future&gt;(tasks.size()); boolean done = false; try { for (Callable t : tasks) { RunnableFuture f = newTaskFor(t); futures.add(f); execute(f); } for (int i = 0, size = futures.size(); i &lt; size; i++) { Future f = futures.get(i); if (!f.isDone()) { try { // 这是一个阻塞方法，直到获取到值，或抛出了异常 // 这里有个小细节，其实 get 方法签名上是会抛出 InterruptedException 的 // 可是这里没有进行处理，而是抛给外层去了。此异常发生于还没执行完的任务被取消了 f.get(); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } } } done = true; return futures; } finally { if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } public List&lt;Future&gt; invokeAll(Collection&lt;? extends Callable&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); ArrayList&lt;Future&gt; futures = new ArrayList&lt;Future&gt;(tasks.size()); boolean done = false; try { for (Callable t : tasks) futures.add(newTaskFor(t)); final long deadline = System.nanoTime() + nanos; final int size = futures.size(); // Interleave time checks and calls to execute in case // executor doesn’t have any/much parallelism. for (int i = 0; i &lt; size; i++) { execute((Runnable)futures.get(i)); nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) return futures; } for (int i = 0; i &lt; size; i++) { Future f = futures.get(i); if (!f.isDone()) { if (nanos &lt;= 0L) return futures; try { f.get(nanos, TimeUnit.NANOSECONDS); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } catch (TimeoutException toe) { return futures; } nanos = deadline - System.nanoTime(); } } done = true; return futures; } finally { if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } }}` 12## 4. java/* The main pool control state, ctl, is an atomic integer packing two conceptual fields workerCount, indicating the effective number of threads runState, indicating whether running, shutting down etc In order to pack them into one int, we limit workerCount to (2^29)-1 (about 500 million) threads rather than (2^31)-1 (2 billion) otherwise representable. If this is ever an issue in the future, the variable can be changed to be an AtomicLong, and the shift/mask constants below adjusted. But until the need arises, this code is a bit faster and simpler using an int. The workerCount is the number of workers that have been permitted to start and not permitted to stop. The value may be transiently different from the actual number of live threads, for example when a ThreadFactory fails to create a thread when asked, and when exiting threads are still performing bookkeeping before terminating. The user-visible pool size is reported as the current size of the workers set. The runState provides the main lifecycle control, taking on values: RUNNING: Accept new tasks and process queued tasks SHUTDOWN: Don’t accept new tasks, but process queued tasks STOP: Don’t accept new tasks, don’t process queued tasks, and interrupt in-progress tasks TIDYING: All tasks have terminated, workerCount is zero, the thread transitioning to state TIDYING will run the terminated() hook method TERMINATED: terminated() has completed The numerical order among these values matters, to allow ordered comparisons. The runState monotonically increases over time, but need not hit each state. The transitions are: RUNNING -&gt; SHUTDOWN On invocation of shutdown(), perhaps implicitly in finalize() (RUNNING or SHUTDOWN) -&gt; STOP On invocation of shutdownNow() SHUTDOWN -&gt; TIDYING When both queue and pool are empty STOP -&gt; TIDYING When pool is empty TIDYING -&gt; TERMINATED When the terminated() hook method has completed Threads waiting in awaitTermination() will return when the state reaches TERMINATED. Detecting the transition from SHUTDOWN to TIDYING is less straightforward than you’d like because the queue may become empty after non-empty and vice versa during SHUTDOWN state, but we can only terminate if, after seeing that it is empty, we see that workerCount is 0 (which sometimes entails a recheck – see below). / private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));public void execute(Runnable command) { if (command == null) throw new NullPointerException(); / Proceed in 3 steps: 1. If fewer than corePoolSize threads are running, try to start a new thread with the given command as its first task. The call to addWorker atomically checks runState and workerCount, and so prevents false alarms that would add threads when it shouldn’t, by returning false. 2. If a task can be successfully queued, then we still need to double-check whether we should have added a thread (because existing ones died since last checking) or that the pool shut down since entry into this method. So we recheck state and if necessary roll back the enqueuing if stopped, or start a new thread if there are none. 3. If we cannot queue task, then we try to add a new thread. If it fails, we know we are shut down or saturated and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); }``","tags":[]},{"title":"protobuf使用","date":"2019-04-10T02:31:04.000Z","path":"2019/04/10/protobuf使用/","text":"安装1234wget https://github.com/protocolbuffers/protobuf/releases/download/v3.6.1/protobuf-all-3.6.1.zipunzop protobuf-all-3.6.1.zipcd protobuf-all-3.6.1./configure &amp;&amp; make &amp;&amp; make install 语法规则123456789101112131415161718192021222324252627282930313233343536// 声明版本，默认是proto2syntax = &quot;proto3&quot;;// 声明包名package tutorialoption java_package = &quot;com.example.tutorial&quot;;// java类名option java_outer_classname = &quot;AddressBookProtos&quot;;message Person &#123; required string name =1; required int32 id = 2; optional string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; required string number = 1; optional PhoneType type = 2[default = HOME]; &#125; repeated PhoneNumber phones = 4;&#125;message AddressBook &#123; repreated Person people = 1;&#125;// 保留字段，编程过程中某些功能没有想好，可以先把该tag 进行保留，以备以后使用。message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;;&#125; 编码 https://blog.csdn.net/zxhoo/article/details/53228303 方法 Standard Message Methods isInitialized(): checks if all the required fields have been set. toString(): returns a human-readable representation of the message, particularly useful for debugging. mergeFrom(Message other): (builder only) merges the contents of other into this message, overwriting singular scalar fields, merging composite fields, and concatenating repeated fields. clear(): (builder only) clears all the fields back to the empty state. Parsing and Serialization byte[] toByteArray();: serializes the message and returns a byte array containing its raw bytes. static Person parseFrom(byte[] data);: parses a message from the given byte array. void writeTo(OutputStream output);: serializes the message and writes it to an OutputStream. static Person parseFrom(InputStream input);: reads and parses a message from an InputStream. 编译注意 升级协议 you must not change the tag numbers of any existing fields. you must not add or delete any required fields. you may delete optional or repeated fields. you may add new optional or repeated fields but you must use fresh tag numbers (i.e. tag numbers that were never used in this protocol buffer, not even by deleted fields). protobuf对repeated压缩不够好，所以尽量在后面加上[packed = true]。 不要让protobuf对象成为全局变量或者类成员，因为其clear方法只会把占用的内存空间清零，而不会释放，使得进程空间越来越大，可参考《Protobuf使用不当导致的程序内存上涨问题》。 https://www.jianshu.com/p/27fdf44dd63b","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"go基本语法","date":"2019-04-10T02:29:55.000Z","path":"2019/04/10/go基本语法/","text":"接口 duck typing了解 在程序设计中，鸭子类型（英语：duck typing）是动态类型的一种风格。在这种风格中，一个对象有效的语义，不是由继承自特定的类或实现特定的接口，而是由“当前方法)和属性的集合”决定。 flagSync1. WaitGroup123Add()Done()Wait() 2. Context12 Regexp https://www.cnblogs.com/golove/p/3269099.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// MatchStringmatched, err := regexp.MatchString(&quot;foo.*&quot;, &quot;seafood&quot;)fmt.Println(matched, err)matched, err = regexp.MatchString(&quot;bar.*&quot;, &quot;seafood&quot;)fmt.Println(matched, err)// false error parsing regexp: missing closing ): `a(b`matched, err = regexp.MatchString(&quot;a(b&quot;, &quot;seafood&quot;)fmt.Println(matched, err)// true &lt;nil&gt;matched, err = regexp.MatchString(`a\\(b`, &quot;a(b&quot;)fmt.Println(matched, err)// false error parsing regexp: missing closing ): `a(b`matched, err = regexp.MatchString(`a(b`, &quot;a(b&quot;)fmt.Println(matched, err)// true &lt;nil&gt;matched, err = regexp.MatchString(&quot;a\\\\(b&quot;, &quot;a(b&quot;)fmt.Println(matched, err)// 将所有特殊字符进行转义fmt.Println(regexp.QuoteMeta(&quot;Escaping symbols like: .+*?()|[]&#123;&#125;^$&quot;))// ExpandStringcontent := ` # comment line option1: value1 option2: value2 # another comment line option3: value3`// Regex pattern captures &quot;key: value&quot; pair from the content.pattern := regexp.MustCompile(`(?m)(?P&lt;key&gt;\\w+):\\s+(?P&lt;value&gt;\\w+)$`)// Template to convert &quot;key: value&quot; to &quot;key=value&quot; by// referencing the values captured by the regex pattern.template := &quot;$key=$value\\n&quot;result := []byte&#123;&#125; // For each match of the regex in the content.for _, submatches := range pattern.FindAllStringSubmatchIndex(content, -1) &#123; // Apply the captured submatches to the template and append the output // to the result. result = pattern.ExpandString(result, template, content, submatches)&#125;fmt.Println(string(result))// findAllStringre := regexp.MustCompile(&quot;a.&quot;)fmt.Println(re.FindAllString(&quot;paranormal&quot;, -1))fmt.Println(re.FindAllString(&quot;paranormal&quot;, 2))fmt.Println(re.FindAllString(&quot;graal&quot;, -1))fmt.Println(re.FindAllString(&quot;none&quot;, -1))// FindAllStringSubmatchre := regexp.MustCompile(&quot;a(x*)b&quot;)fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-ab-&quot;, -1))fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-axxb-&quot;, -1))fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-ab-axb-&quot;, -1))fmt.Printf(&quot;%q\\n&quot;, re.FindAllStringSubmatch(&quot;-axxb-ab-&quot;, -1))// findStringSubmatch，只查找第一个re := regexp.MustCompile(&quot;a(x*)b(y|z)c&quot;)fmt.Printf(&quot;%q\\n&quot;, re.FindStringSubmatch(&quot;-axxxbyc-&quot;))fmt.Printf(&quot;%q\\n&quot;, re.FindStringSubmatch(&quot;-abzc-&quot;))","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"makefile编写","date":"2019-04-10T02:27:53.000Z","path":"2019/04/10/makefile编写/","text":"例子12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091.PHONY: build clean test package package-deb ui api statics requirements ui-requirements serve update-vendor internal/statics internal/migrations static/swagger/api.swagger.jsonPKGS := $(shell go list ./... | grep -v /vendor |grep -v lora-app-server/api | grep -v /migrations | grep -v /static | grep -v /ui)VERSION := $(shell git describe --always |sed -e &quot;s/^v//&quot;)build: ui/build internal/statics internal/migrations mkdir -p build go build $(GO_EXTRA_BUILD_ARGS) -ldflags &quot;-s -w -X main.version=$(VERSION)&quot; -o build/lora-app-server cmd/lora-app-server/main.goclean: @echo &quot;Cleaning up workspace&quot; @rm -rf build dist internal/migrations internal/static ui/build static/static @rm -f static/index.html static/icon.png static/manifest.json static/asset-manifest.json static/service-worker.js @rm -rf static/logo @rm -rf docs/public @rm -rf disttest: internal/statics internal/migrations @echo &quot;Running tests&quot; @for pkg in $(PKGS) ; do \\ golint $$pkg ; \\ done @go vet $(PKGS) @go test -p 1 -v $(PKGS)documentation: @echo &quot;Building documentation&quot; @mkdir -p dist/docs @cd docs &amp;&amp; hugo @cd docs/public/ &amp;&amp; tar -pczf ../../dist/lora-app-server-documentation.tar.gz .dist: ui/build internal/statics internal/migrations @goreleaserbuild-snapshot: ui/build internal/statics internal/migrations @goreleaser --snapshotpackage-deb: package @echo &quot;Building deb package&quot; @cd packaging &amp;&amp; TARGET=deb ./package.shui/build: @echo &quot;Building ui&quot; @cd ui &amp;&amp; npm run build @mv ui/build/* staticapi: @echo &quot;Generating API code from .proto files&quot; @go generate api/api.gointernal/statics internal/migrations: static/swagger/api.swagger.json @echo &quot;Generating static files&quot; @go generate cmd/lora-app-server/main.gostatic/swagger/api.swagger.json: @echo &quot;Generating combined Swagger JSON&quot; @GOOS=&quot;&quot; GOARCH=&quot;&quot; go run api/swagger/main.go api/swagger &gt; static/swagger/api.swagger.json @cp api/swagger/*.json static/swagger# shortcuts for developmentrequirements: echo &quot;Installing development tools&quot; go get -u github.com/golang/lint/golint go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gateway go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-swagger go get -u github.com/golang/protobuf/protoc-gen-go go get -u github.com/elazarl/go-bindata-assetfs/... go get -u github.com/jteeuwen/go-bindata/... go get -u github.com/kisielk/errcheck go get -u github.com/smartystreets/goconvey go get -u golang.org/x/tools/cmd/stringer go get -u github.com/golang/dep/cmd/dep go get -u github.com/goreleaser/goreleaser dep ensure -vui-requirements: @echo &quot;Installing UI requirements&quot; @cd ui &amp;&amp; npm installserve: build @echo &quot;Starting Lora App Server&quot; ./build/lora-app-serverupdate-vendor: @echo &quot;Updating vendored packages&quot; @govendor update +externalrun-compose-test: docker-compose run --rm appserver make test 文件格式12&lt;target&gt; : &lt;prerequisites&gt; [tab] &lt;commands&gt; target：执行的命令或者文件名。如果只是执行的命令这是伪指令，在大部分时候使用.PHONY声明伪指令，这样不仅仅提供效率，同时也避免和文件名冲突。 prerequisites：前置条件。 commands：需要执行的命令， 前面需要添加[tab]，如果想要换成其他的，使用.RECIPEPREFIX = ？换成你喜欢的。 执行命令的时候会打印出相关的命令内容，这个叫做回显，如果不想显示出来可以在命令前面添加@。 命令执行的时候，每行命令在不同一个shell中执行，如果想在同一个shell中执行，有下面几个办法。 将命令写在同一行 在命令后面添加\\，实现命令多行 使用.ONESHELL: 内置变量makefile可以通过=、:=、?=、+=给变量赋值，同时Make命令提供一系列内置变量，比如，((CC)指向当前使用的编译器，)(MAKE) 指向当前使用的Make工具。这主要是为了跨平台的兼容性，详细的内置变量清单见手册。 参考https://blog.csdn.net/u010230971/article/details/80335613 https://www.cnblogs.com/wang_yb/p/3990952.html http://www.ruanyifeng.com/blog/2015/02/make.html","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"mybatis-sessions","date":"2019-04-10T02:25:51.000Z","path":"2019/04/10/mybatis-sessions/","text":"SqlSessionFactorysqlSessionFactory是工厂类的接口，默认实现是DefaultSqlSessionFactory，通过sqlSessionFactoryBuilder创建，我们不具体讨论配置文件的具体解析，主要分析mybatis的运行流程。 SqlSessionFactory主要是用来创建SqlSession，SqlSession是线程不安全的，因此每次操作都要重新创建。 12345678910111213141516171819202122// 通过数据源创建SqlSession，是我们比较常用的一种方式private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); //通过事务工厂来产生一个事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //生成一个执行器(事务包含在执行器里) final Executor executor = configuration.newExecutor(tx, execType); //然后产生一个DefaultSqlSession return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; //如果打开事务出错，则关闭它 closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); &#125; finally &#123; //最后清空错误上下文 ErrorContext.instance().reset(); &#125; &#125;SqlSession SqlSession有两方式调用方法，第一种方式是通过命名空间调用，第二种方式是JavaBean调用，也就是通过我们常用的Mapper接口进行调用。现在Myabtis3我们基本使用第二种方式。 通过Mapper接口进行调用，核心是 获取Mapper接口，并通过动态代理，进行方法拦截。 SqlSession通过getMapper获取相应的Mapper接口。SqlSession的的数据库操作是调用Executor的相关方法。 在getMapper调用的时候，有几个核心的类 MapperProxyFactory:用于创建MapperProxyd的工厂方法 MapperProxy:动态代理的InvocationHandler的实现，实际中就是执行sql语句 MapperRegistry MapperMethood:调用SqlSession的方法","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"http://wumuwumu.github.io/tags/mybatis/"}]},{"title":"git基本操作","date":"2019-04-09T05:59:25.000Z","path":"2019/04/09/git基本操作/","text":"简介在实际开发中，会使用git作为版本控制工具来完成团队协作。因此，对基本的git操作指令进行总结是十分有必要的，本文对一些术语或者理论基础，不重新码字，可以参考廖雪峰老师的博文，本文只对命令做归纳总结。 git的通用操作流程如下图（来源于网络） 主要涉及到四个关键点： 工作区：本地电脑存放项目文件的地方，比如learnGitProject文件夹； 暂存区（Index/Stage）：在使用git管理项目文件的时候，其本地的项目文件会多出一个.git的文件夹，将这个.git文件夹称之为版本库。其中.git文件夹中包含了两个部分，一个是暂存区（Index或者Stage）,顾名思义就是暂时存放文件的地方，通常使用add命令将工作区的文件添加到暂存区里； 本地仓库：.git文件夹里还包括git自动创建的master分支，并且将HEAD指针指向master分支。使用commit命令可以将暂存区中的文件添加到本地仓库中； 远程仓库：不是在本地仓库中，项目代码在远程git服务器上，比如项目放在github上，就是一个远程仓库，通常使用clone命令将远程仓库拷贝到本地仓库中，开发后推送到远程仓库中即可； 更细节的来看： 日常开发时代码实际上放置在工作区中，也就是本地的XXX.java这些文件，通过add等这些命令将代码文教提交给暂存区（Index/Stage），也就意味着代码全权交给了git进行管理，之后通过commit等命令将暂存区提交给master分支上，也就是意味打了一个版本，也可以说代码提交到了本地仓库中。另外，团队协作过程中自然而然还涉及到与远程仓库的交互。 因此，经过这样的分析，git命令可以分为这样的逻辑进行理解和记忆： git管理配置的命令； 几个核心存储区的交互命令： 工作区与暂存区的交互； 暂存区与本地仓库（分支）上的交互； 本地仓库与远程仓库的交互。 安装git安装 https://git-scm.com/ 配置123456$ git config --global user.name \"Your Name\"$ git config --global user.email \"email@example.com\"$ git config --global core.editor emacs$ git config --list$ git config user.name 快速开始1234$ git init # 初始化工程$ git add * # 将文件添加到暂存区$ git commit -m # 提交$ git clone https://github.com/libgit2/libgit2 常用命令add git add -A 保存所有的修改 git add . 保存新的添加和修改，但是不包括删除 git add -u 保存修改和删除，但是不包括新建文件。 commit git commit -m git commit -ma // -a是添加全部修改 git commit –amend checkout git checkout — //使用暂缓区替换工作区 git checkout 切换分支 git checkout head — //直接使用本地参考的文件覆盖工作区文件 rm git rm // 删除工作区，并且提交 git rm —cached // 只删除暂存区 git rm -f // 暂存区和工作区都删除 reset谨慎使用！！！！！ –soft – 缓存区和工作目录都不会被改变 –mixed – 默认选项。缓存区和你指定的提交同步，但工作目录不受影响 –hard – 缓存区和工作目录都同步到你指定的提交 revert前提是已经提交，缺点：一次回滚过个记录会出现冲突。","tags":[{"name":"git","slug":"git","permalink":"http://wumuwumu.github.io/tags/git/"}]},{"title":"go工程搭建","date":"2019-04-09T01:26:21.000Z","path":"2019/04/09/go/go工程搭建/","text":"工程基本结构","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"mysql权限管理","date":"2019-03-29T08:55:22.000Z","path":"2019/03/29/mysql/mysql权限管理/","text":"用户管理基本操作12345678create user zhangsan identified by 'zhangsan';SELECT current_user(); ← 查看当前用户SELECT user,host FROM mysql.user; ← 查看用户信息SHOW GRANTS; ← 当前用户权限，会生成SQL语句CREATE USER 'user'@'host' IDENTIFIED BY 'password'; ← 创建用户DROP USER 'user'@'host'; ← 删除用户RENAME USER 'user'@'host' TO 'fool'@'host'; 修改密码12345678mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'new-password'; ← 修改密码(recommand)mysql&gt; SET PASSWORD FOR 'root'@'localhost'=PASSWORD('new-password'); ← 修改密码mysql&gt; UPDATE mysql.user SET password=PASSWORD('new-password') WHERE USER='root' AND Host='127.0.0.1';mysql&gt; UPDATE mysql.user SET password='' WHERE user='root'; ← 清除密码mysql&gt; FLUSH PRIVILEGES;$ mysqladmin -uROOT -pOLD_PASSWD password NEW_PASSWD ← 通过mysqladmin修改$ mysqladmin -uROOT -p flush-privileges 权限管理1234567891011mysql&gt; GRANT ALL ON *.* TO 'user'@'%' [IDENTIFIED BY 'password'];mysql&gt; GRANT ALL PRIVILIGES ON [TABLE | DATABASE] student,course TO user1,user2;mysql&gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE TEMPORARY, ALTER, DROP, REFERENCES, INDEX, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EXECUTE ON db.tbl TO 'user'@'host' [IDENTIFIED BY 'password'];mysql&gt; GRANT ALL ON sampdb.* TO PUBLIC WITH GRANT OPTION; ← 所有人，可以授权给其他人mysql&gt; GRANT UPDATE(col),SELECT ON TABLE tbl TO user; ← 针对列赋值mysql&gt; SHOW GRANTS [FOR 'user'@'host']; ← 查看权限信息mysql&gt; REVOKE ALL ON *.* FROM 'user'@'host'; ← 撤销权限mysql&gt; REVOKE SELECT(user, host), UPDATE(host) ON db.tbl FROM 'user'@'%'; 权限admin12345mysql&gt; CREATE USER &apos;admin&apos;@&apos;IP&apos; IDENTIFIED BY &apos;password&apos;;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;admin&apos;@&apos;IP&apos;;mysql&gt; REVOKE ALL PRIVILEGES ON *.* FROM &apos;admin&apos;@&apos;IP&apos;;mysql&gt; DROP USER &apos;admin&apos;@&apos;IP&apos;; root1mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION; 其他重置root密码123456789101112131415161718----- 1. 停止mysql服务器# systemctl stop mysqld# /opt/mysql-5.7/bin/mysqladmin -uroot -p'init-password' shutdownShutting down MySQL.. done----- 2. 获取跳过认证的启动参数# mysqld --help --verbose | grep 'skip-grant-tables' -A1 --skip-grant-tables Start without grant tables. This gives all users FULL ACCESS to all tables.----- 3. 启动服务器，跳过认证# mysqld --skip-grant-tables --user=mysql &amp;[1] 10209----- 4. 取消密码mysql&gt; UPDATE mysql.user SET password='' WHERE user='root';Query OK, 2 rows affected (0.00 sec)Rows matched: 2 Changed: 2 Warnings: 0 MySQL 中 localhost 127.0.0.1 区别% 是一个通配符，用以匹配所有的 IP 地址，但是不能匹配到 locahost 这个特殊的域名。 也就是说，如果要允许本地登录，单纯只配置一个 % 是不够的 (应该是说对这种方式是不够的)，需要同时配置一个 locahost 的账号。 123456789101112mysql&gt; GRANT ALL ON *.* TO 'foobar'@'%' IDENTIFIED BY '123456';Query OK, 0 rows affected (0.01 sec)mysql&gt; SELECT user, host, password FROM mysql.user WHERE user like 'foobar%';+--------+------+-------------------------------------------+| user | host | password |+--------+------+-------------------------------------------+| foobar | % | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |+--------+------+-------------------------------------------+1 row in set (0.00 sec)$ mysql -ufoobar -h127.0.0.1 -P3307 -p'123456'ERROR 1045 (28000): Access denied for user 'foobar'@'localhost' (using password: YES) https://jin-yang.github.io/post/mysql-localhost-vs-127.0.0.1-introduce.html 参考https://jin-yang.github.io/post/mysql-users.html https://www.cnblogs.com/Richardzhu/p/3318595.html","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos安装mysql","date":"2019-03-29T07:45:32.000Z","path":"2019/03/29/mysql/mysql安装/","text":"添加 MySQL YUM 源123456$wget &apos;https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm&apos;$sudo rpm -Uvh mysql57-community-release-el7-11.noarch.rpm$yum repolist all | grep mysqlmysql-connectors-community/x86_64 MySQL Connectors Community 36mysql-tools-community/x86_64 MySQL Tools Community 47mysql57-community/x86_64 MySQL 5.7 Community Server 187 安装MySQL12345678910111213141516171819202122232425## 安装最新版$sudo yum install mysql-community-server$ sudo yum install mysql ## 安装客户端## 安装老版本## 1. yum-config-manager$ sudo dnf config-manager --disable mysql57-community$ sudo dnf config-manager --enable mysql56-community$ yum repolist | grep mysqlmysql-connectors-community/x86_64 MySQL Connectors Community 36mysql-tools-community/x86_64 MySQL Tools Community 47mysql56-community/x86_64 MySQL 5.6 Community Server 327## 2. 直接修改 /etc/yum.repos.d/mysql-community.repo# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/7/$basearch/enabled=1 #表示当前版本是安装gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/$basearch/enabled=0 #默认这个是 1gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 启动Mysql123456789101112$sudo service mysqld start $sudo systemctl start mysqld #CentOS 7$sudo systemctl status mysqld● mysqld.service - MySQL Community Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-05-27 12:56:26 CST; 15s ago Process: 2482 ExecStartPost=/usr/bin/mysql-systemd-start post (code=exited, status=0/SUCCESS) Process: 2421 ExecStartPre=/usr/bin/mysql-systemd-start pre (code=exited, status=0/SUCCESS) Main PID: 2481 (mysqld_safe) CGroup: /system.slice/mysqld.service ├─2481 /bin/sh /usr/bin/mysqld_safe --basedir=/usr └─2647 /usr/sbin/mysqld --basedir=/usr --datadir=/var/lib/mysql --plugin-dir=/usr/... 修改密码1234## 获取临时密码sudo grep &apos;temporary password&apos; /var/log/mysqld.log$ mysql -uroot -p #输入查看到的密码mysql&gt; ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;MyNewPass4!&apos;; mysql的密码存在安全等级 1shell&gt; mysql_secure_installation 1mysql&gt; SHOW VARIABLES LIKE &apos;validate_password%&apos;; validate_password_number_count参数是密码中至少含有的数字个数，当密码策略是MEDIUM或以上时生效。 validate_password_special_char_count参数是密码中非英文数字等特殊字符的个数，当密码策略是MEDIUM或以上时生效。 validate_password_mixed_case_count参数是密码中英文字符大小写的个数，当密码策略是MEDIUM或以上时生效。 validate_password_length参数是密码的长度，这个参数由下面的公式生成 validate_password_number_count+ validate_password_special_char_count+ (2 * validate_password_mixed_case_count) validate_password_dictionary_file参数是指定密码验证的字典文件路径。 validate_password_policy这个参数可以设为0、1、2，分别代表从低到高的密码强度，此参数的默认值为1，如果想将密码强度改弱，则更改此参数为0。 修改密码策略更改密码策略为LOW 1mysql&gt; set global validate_password_policy=0; 更改密码长度 1mysql&gt; set global validate_password_length=0; 安全设置1234567## 会提示设置5个关键位置## 设置 root 密码## 禁止 root 账号远程登录## 禁止匿名账号（anonymous）登录## 删除测试库## 是否确认修改$ mysql_secure_installation 安装三方插件1yum --disablerepo=\\* --enablerepo=&apos;mysql*-community*&apos; list available 修改编码123456789## /etc/my.cnf[client]default-character-set = utf8[mysqld]default-storage-engine = INNODBcharacter-set-server = utf8collation-server = utf8_general_ci #不区分大小写collation-server = utf8_bin #区分大小写collation-server = utf8_unicode_ci #比 utf8_general_ci 更准确 修改服务器时间123456789101112131415## mysql 中默认的时间戳是 UTC 时间，需要改为服务器时间的话官网提供了 3 种方式$ mysql_tzinfo_to_sql tz_dir$ mysql_tzinfo_to_sql tz_file tz_name$ mysql_tzinfo_to_sql --leap tz_file## tz_dir 代表服务器时间数据库，CentOS 7 中默认的目录为 /usr/share/zoneinfo ，tz_name 为具体的时区。如果设置的时区需要闰秒，则使用 --leap，具体的用法如下：$ mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root -p mysql$ mysql_tzinfo_to_sql tz_file tz_name | mysql -u root mysql$ mysql_tzinfo_to_sql --leap tz_file | mysql -u root mysql&gt; set global time_zone = &apos;+8:00&apos;; ##修改mysql全局时区为北京时间，即我们所在的东8区&gt; set time_zone = &apos;+8:00&apos;; ##修改当前会话时区&gt; flush privileges; #立即生效## 通过修改my.cnf配置文件来修改时区# vim /etc/my.cnf ##在[mysqld]区域中加上default-time_zone = &apos;+8:00&apos;# /etc/init.d/mysqld restart ##重启mysql使新时区生效","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"ngrok环境搭建","date":"2019-03-29T01:28:43.000Z","path":"2019/03/29/ngrok环境搭建/","text":"下载安装 配置golang环境 安装go 1yum install golang 配置GOPATH 安装git2 1234sudo yum remove gitsudo yum install epel-releasesudo yum install https://centos7.iuscommunity.org/ius-release.rpmsudo yum install git2u 下载ngrok 1go get github.com/inconshreveable/ngrok 生成证书 使用let’s encrypt证书 申请证书（具体看申请证书，主要通配符证书和三级域名） 修改证书 客户端证书 12cd ngrokcp /etc/letsencrypt/live/xncoding.com/chain.pem assets/client/tls/ngrokroot.crt 服务端证书 12cp /etc/letsencrypt/live/xncoding.com/cert.pem assets/server/tls/snakeoil.crtcp /etc/letsencrypt/live/xncoding.com/privkey.pem assets/server/tls/snakeoil.key 编译 编译服务端 1make release-server 编译客户端 不同平台的客户端需要分开编译。不同平台使用不同的 GOOS 和 GOARCH，GOOS为go编译出来的操作系统 (windows,linux,darwin)，GOARCH, 对应的构架 (386,amd64,arm) 123GOOS=linux GOARCH=amd64 make release-clientGOOS=windows GOARCH=amd64 make release-clientGOOS=linux GOARCH=arm make release-client 启动服务器在开启之前，请主要端口是否开放 1./ngrokd -domain=ngrok.sciento.top -httpAddr=:9580 -httpsAddr=:9443 -tunnelAddr=\":9444\" 启动客户端 配置文件,具体看官方文档 123456789101112server_addr: &quot;ngrok.sciento.top:9444&quot;trust_host_root_certs: falsetunnels: http: subdomain: &quot;demo&quot; proto: http: &quot;9000&quot; https: subdomain: &quot;demo&quot; proto: https: &quot;9000&quot; 启动 1./ngrok -config=ngrok.cfg start http https nginx配置 安装nginx 配置 123456789101112131415161718192021222324252627server &#123; listen 80; server_name demo.ngrok.xncoding.com; return 301 https://demo.ngrok.xncoding.com$request_uri;&#125;server &#123; listen 443 ssl http2; server_name demo.ngrok.xncoding.com; charset utf-8; ssl_certificate /etc/letsencrypt/live/demo.ngrok.xncoding.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/demo.ngrok.xncoding.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/demo.ngrok.xncoding.com/chain.pem; access_log /var/log/nginx/ngrok.log main; error_log /var/log/nginx/ngrok_error.log error; location / &#123; proxy_pass http://127.0.0.1:5442; proxy_redirect off; proxy_set_header Host $http_host:5442; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 参考https://www.xncoding.com/2017/12/29/web/ngrok.html https://www.coldawn.com/how-to-issue-acmev2-wildcard-certificates-with-certbot-on-centos-7/ https://www.jianshu.com/p/c5c9d071e395 http://ngrok.cn/docs.html#tcp","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"Druid初始化","date":"2019-03-25T10:17:33.000Z","path":"2019/03/25/Druid初始化/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236public void init() throws SQLException &#123; if (inited) &#123; return; &#125; // bug fixed for dead lock, for issue #2980 DruidDriver.getInstance(); final ReentrantLock lock = this.lock; try &#123; lock.lockInterruptibly(); &#125; catch (InterruptedException e) &#123; throw new SQLException(\"interrupt\", e); &#125; boolean init = false; try &#123; //双重检查 if (inited) &#123; return; &#125; initStackTrace = Utils.toString(Thread.currentThread().getStackTrace()); this.id = DruidDriver.createDataSourceId(); if (this.id &gt; 1) &#123; long delta = (this.id - 1) * 100000; this.connectionIdSeedUpdater.addAndGet(this, delta); this.statementIdSeedUpdater.addAndGet(this, delta); this.resultSetIdSeedUpdater.addAndGet(this, delta); this.transactionIdSeedUpdater.addAndGet(this, delta); &#125; if (this.jdbcUrl != null) &#123; this.jdbcUrl = this.jdbcUrl.trim(); initFromWrapDriverUrl(); &#125; for (Filter filter : filters) &#123; filter.init(this); &#125; if (this.dbType == null || this.dbType.length() == 0) &#123; this.dbType = JdbcUtils.getDbType(jdbcUrl, null); &#125; if (JdbcConstants.MYSQL.equals(this.dbType) || JdbcConstants.MARIADB.equals(this.dbType) || JdbcConstants.ALIYUN_ADS.equals(this.dbType)) &#123; boolean cacheServerConfigurationSet = false; if (this.connectProperties.containsKey(\"cacheServerConfiguration\")) &#123; cacheServerConfigurationSet = true; &#125; else if (this.jdbcUrl.indexOf(\"cacheServerConfiguration\") != -1) &#123; cacheServerConfigurationSet = true; &#125; if (cacheServerConfigurationSet) &#123; this.connectProperties.put(\"cacheServerConfiguration\", \"true\"); &#125; &#125; if (maxActive &lt;= 0) &#123; throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); &#125; if (maxActive &lt; minIdle) &#123; throw new IllegalArgumentException(\"illegal maxActive \" + maxActive); &#125; if (getInitialSize() &gt; maxActive) &#123; throw new IllegalArgumentException(\"illegal initialSize \" + this.initialSize + \", maxActive \" + maxActive); &#125; if (timeBetweenLogStatsMillis &gt; 0 &amp;&amp; useGlobalDataSourceStat) &#123; throw new IllegalArgumentException(\"timeBetweenLogStatsMillis not support useGlobalDataSourceStat=true\"); &#125; if (maxEvictableIdleTimeMillis &lt; minEvictableIdleTimeMillis) &#123; throw new SQLException(\"maxEvictableIdleTimeMillis must be grater than minEvictableIdleTimeMillis\"); &#125; if (this.driverClass != null) &#123; this.driverClass = driverClass.trim(); &#125; initFromSPIServiceLoader(); // 处理驱动 if (this.driver == null) &#123; if (this.driverClass == null || this.driverClass.isEmpty()) &#123; this.driverClass = JdbcUtils.getDriverClassName(this.jdbcUrl); &#125; if (MockDriver.class.getName().equals(driverClass)) &#123; driver = MockDriver.instance; &#125; else &#123; if (jdbcUrl == null &amp;&amp; (driverClass == null || driverClass.length() == 0)) &#123; throw new SQLException(\"url not set\"); &#125; driver = JdbcUtils.createDriver(driverClassLoader, driverClass); &#125; &#125; else &#123; if (this.driverClass == null) &#123; this.driverClass = driver.getClass().getName(); &#125; &#125; // 进行参数的核对，没有什么逻辑 initCheck(); // 为不同的数据库处理异常，这个可以借鉴 initExceptionSorter(); initValidConnectionChecker(); // 做了一些检查，不知道 validationQueryCheck(); // 创建数据统计对象 if (isUseGlobalDataSourceStat()) &#123; dataSourceStat = JdbcDataSourceStat.getGlobal(); if (dataSourceStat == null) &#123; dataSourceStat = new JdbcDataSourceStat(\"Global\", \"Global\", this.dbType); JdbcDataSourceStat.setGlobal(dataSourceStat); &#125; if (dataSourceStat.getDbType() == null) &#123; dataSourceStat.setDbType(this.dbType); &#125; &#125; else &#123; dataSourceStat = new JdbcDataSourceStat(this.name, this.jdbcUrl, this.dbType, this.connectProperties); &#125; dataSourceStat.setResetStatEnable(this.resetStatEnable); // 创建连接池 connections = new DruidConnectionHolder[maxActive]; evictConnections = new DruidConnectionHolder[maxActive]; keepAliveConnections = new DruidConnectionHolder[maxActive]; SQLException connectError = null; // 同步或者异步创建线程池 if (createScheduler != null &amp;&amp; asyncInit) &#123; for (int i = 0; i &lt; initialSize; ++i) &#123; createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); &#125; &#125; else if (!asyncInit) &#123; // init connections while (poolingCount &lt; initialSize) &#123; try &#123; PhysicalConnectionInfo pyConnectInfo = createPhysicalConnection(); DruidConnectionHolder holder = new DruidConnectionHolder(this, pyConnectInfo); connections[poolingCount++] = holder; &#125; catch (SQLException ex) &#123; LOG.error(\"init datasource error, url: \" + this.getUrl(), ex); if (initExceptionThrow) &#123; connectError = ex; break; &#125; else &#123; Thread.sleep(3000); &#125; &#125; &#125; if (poolingCount &gt; 0) &#123; poolingPeak = poolingCount; poolingPeakTime = System.currentTimeMillis(); &#125; &#125; // 用来打印线程池 createAndLogThread(); createAndStartCreatorThread(); // 停止 createAndStartDestroyThread(); // 等待线程创建完成 initedLatch.await(); init = true; initedTime = new Date(); // 注册mbean registerMbean(); if (connectError != null &amp;&amp; poolingCount == 0) &#123; throw connectError; &#125; // 检查连接池，防止连接池超出最大连接池 if (keepAlive) &#123; // async fill to minIdle if (createScheduler != null) &#123; for (int i = 0; i &lt; minIdle; ++i) &#123; createTaskCount++; CreateConnectionTask task = new CreateConnectionTask(true); this.createSchedulerFuture = createScheduler.submit(task); &#125; &#125; else &#123; this.emptySignal(); &#125; &#125; &#125; catch (SQLException e) &#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; catch (InterruptedException e) &#123; throw new SQLException(e.getMessage(), e); &#125; catch (RuntimeException e)&#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; catch (Error e)&#123; LOG.error(\"&#123;dataSource-\" + this.getID() + \"&#125; init error\", e); throw e; &#125; finally &#123; // 初始化成功 inited = true; // 解锁 lock.unlock(); if (init &amp;&amp; LOG.isInfoEnabled()) &#123; String msg = \"&#123;dataSource-\" + this.getID(); if (this.name != null &amp;&amp; !this.name.isEmpty()) &#123; msg += \",\"; msg += this.name; &#125; msg += \"&#125; inited\"; LOG.info(msg); &#125; &#125; &#125;","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"java多线程","date":"2019-02-15T08:37:30.000Z","path":"2019/02/15/java多线程/","text":"相关的类 Runnable Thread Callable:比Runnable有个返回值 Future FutureTask","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"sqlx基本使用","date":"2019-02-13T08:15:58.000Z","path":"2019/02/13/go/sqlx基本使用/","text":"安装1go get github.com/jmoiron/sqlx 连接数据库12345678910var db *sqlx.DB // exactly the same as the built-indb = sqlx.Open(\"sqlite3\", \":memory:\") // from a pre-existing sql.DB; note the required driverNamedb = sqlx.NewDb(sql.Open(\"sqlite3\", \":memory:\"), \"sqlite3\") // force a connection and test that it workederr = db.Ping() 查询Exec直接执行，适合add,update,delete 1234567891011121314schema := `CREATE TABLE place ( country text, city text NULL, telcode integer);` // execute a query on the serverresult, err := db.Exec(schema) // or, you can use MustExec, which panics on errorcityState := `INSERT INTO place (country, telcode) VALUES (?, ?)`countryCity := `INSERT INTO place (country, city, telcode) VALUES (?, ?, ?)`db.MustExec(cityState, \"Hong Kong\", 852)db.MustExec(cityState, \"Singapore\", 65)db.MustExec(countryCity, \"South Africa\", \"Johannesburg\", 27) Query查询数据库，适合select 12345678910111213141516171819202122// fetch all places from the dbrows, err := db.Query(\"SELECT country, city, telcode FROM place\") // iterate over each rowfor rows.Next() &#123; var country string // note that city can be NULL, so we use the NullString type var city sql.NullString var telcode int err = rows.Scan(&amp;country, &amp;city, &amp;telcode)&#125;// queryx 可以对结果转换成结构体var person2 User rowxs,err :=db.Queryx(\"SELECT * FROM sys_user LIMIT 1\") if err != nil&#123; panic(err) &#125; for rowxs.Next()&#123; rowxs.StructScan(&amp;person2) fmt.Println(person2) &#125; Select12345678910111213141516p := Place&#123;&#125;pp := []Place&#123;&#125; // this will pull the first place directly into perr = db.Get(&amp;p, \"SELECT * FROM place LIMIT 1\") // this will pull places with telcode &gt; 50 into the slice pperr = db.Select(&amp;pp, \"SELECT * FROM place WHERE telcode &gt; ?\", 50) // they work with regular types as wellvar id interr = db.Get(&amp;id, \"SELECT count(*) FROM place\") // fetch at most 10 place namesvar names []stringerr = db.Select(&amp;names, \"SELECT name FROM place LIMIT 10\") 事务1234// this will not work if connection pool &gt; 1db.MustExec(\"BEGIN;\")db.MustExec(...)db.MustExec(\"COMMIT;\") 预编译123456stmt, err := db.Prepare(`SELECT * FROM place WHERE telcode=?`)row = stmt.QueryRow(65) tx, err := db.Begin()txStmt, err := tx.Prepare(`SELECT * FROM place WHERE telcode=?`)row = txStmt.QueryRow(852) Named Queries12345678910111213141516171819202122232425// named query with a structp := Place&#123;Country: \"South Africa\"&#125;rows, err := db.NamedQuery(`SELECT * FROM place WHERE country=:country`, p) // named query with a mapm := map[string]interface&#123;&#125;&#123;\"city\": \"Johannesburg\"&#125;result, err := db.NamedExec(`SELECT * FROM place WHERE city=:city`, m)p := Place&#123;TelephoneCode: 50&#125;pp := []Place&#123;&#125; // select all telcodes &gt; 50nstmt, err := db.PrepareNamed(`SELECT * FROM place WHERE telcode &gt; :telcode`)err = nstmt.Select(&amp;pp, p)arg := map[string]interface&#123;&#125;&#123; \"published\": true, \"authors\": []&#123;8, 19, 32, 44&#125;,&#125;query, args, err := sqlx.Named(\"SELECT * FROM articles WHERE published=:published AND author_id IN (:authors)\", arg)query, args, err := sqlx.In(query, args...)query = db.Rebind(query)db.Query(query, args...) 参考 http://jmoiron.github.io/sqlx/","tags":[{"name":"go","slug":"go","permalink":"http://wumuwumu.github.io/tags/go/"}]},{"title":"jquery基本操作","date":"2019-01-12T08:20:45.000Z","path":"2019/01/12/jquery基本操作/","text":"选择器123456789101112// 基本选择器$('#id')$('.class')$('element')$('*')$('select1 ,select2')//可以使用css选择器// 层次选择器$('ancestor descendant')$('parent &gt;child')$('prev+next')$('prev~siblings')//获取所有同辈元素 DOM操作基本操作123456789101112131415161718192021222324252627282930313233343536// attr$('div').attr(\"background\")//获取属性$('div').attr(\"background\",\"white\")$('div').attr(&#123;\"background\":\"white\",\"height\":\"200px\"&#125;)// css$(\"div\").css('background')$('div').css(\"background\",\"white\")$('div').css(&#123;'background':'blue',\"height\":'200px'&#125;)// width heightwidth()height()// addClass$('div').addClass('className');// removeAttr$('div').removeAttr('background')// removeClass 没参数删除所有// hasClass// 创建节点var p $('&lt;p&gt;hello&lt;/p&gt;')// append() 添加内容// appendTo()// prepend() 向元素内部前面添加内容// prependTo()​``` html&lt;p&gt;hello&lt;/p&gt;​ $(‘hi!‘).prependTo(“p”)​12&lt;p&gt;&lt;i&gt;hi!&lt;/i&gt;hello&lt;/p&gt;​ // 在相应位置添加元素，是在元素的外面// after// insertAfter// before//insertBefore // remove()// detach()：和remove()几乎一样，不同的是detach方法不会删除节点所绑定的事件和附加的数据// empty() 清空内容 // clone()复制节点，可以有参数true，当有true参数时，将同时复制节点所绑定的事件// replaceWith 将匹配的节点替换成指定的节点// replaceAll() 只是用一个 // wrap 包裹节点// wrapAll// wrapInner 将匹配的节点内部的节点或者文本内容用指定的节点包裹起来​12&lt;p&gt;我是内容&lt;/p&gt;​ $(“p”).wrapInner(““);​12&lt;p&gt;&lt;span&gt;我是内容&lt;/span&gt;&lt;/p&gt;​ // html()// text()// val() // children()// next()// prev()// siblings()// closest() 获取最近的符合匹配的一个父元素​123456&lt;div&gt;&lt;div class=&quot;div2&quot;&gt;&lt;p&gt;我是内容&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;​ var $div=$(“p”).closest();//返回class为div2的div元素 // parent()// parents() // offset()// position() // scrollTop()// scrollLeft() 1234567891011121314151617181920212223242526272829303132# 事件与动画```js$().ready()$(&apos;&apos;).bind(type,func)$(&apos;&apos;).click()$(&apos;&apos;).mouseover// 合成事件hover(enter,leave)toggle(fn1,fn2) // 阻止事件event.stopPropagation();event.preventDefault();// unbind 移除事件// trigger 触发事件// 动画hide();show(time);fadeLn();fadeOut();slideUp();slideDown();slideToggle();fadeTo();fadeToggle();animate();delay(); 参考 jQuery简明参考手册——30分钟快速入门jQuery","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"},{"name":"jquery","slug":"jquery","permalink":"http://wumuwumu.github.io/tags/jquery/"}]},{"title":"springcloud-eureka","date":"2019-01-06T10:27:25.000Z","path":"2019/01/06/springcloud-eureka/","text":"建立工程 添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt;&lt;/dependency&gt; 添加Application 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] arg)&#123; SpringApplication.run(EurekaApplication.class,arg); &#125;&#125; 添加配置文件 123456789101112131415server: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false ## 是否注册到eureka server fetchRegistry: false ## 是否获取Eureka server 注册信息，单机可以设置为false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ ## 默认http://localhost:8761/eurekaspring: application: name: eurka-server 运行工程，访问127.0.0.1:9761可以看到web界面。 安全 添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; 添加配置 老版本 123456security: basic: true user: name: wumu password: wumu 新版本 1234security: user: name: wumu password: wumu 问题 在依赖包中同时添加的spring-cloud-starter-netflix-eureka-server与springb-boot-starter-web两个依赖会导致tomcat的依赖问题，应用不能启动。","tags":[{"name":"spring-cloud","slug":"spring-cloud","permalink":"http://wumuwumu.github.io/tags/spring-cloud/"}]},{"title":"Tiemline设计方案","date":"2019-01-04T12:33:08.000Z","path":"2019/01/04/Tiemline设计方案/","text":"参考 朋友圈式的TIMELINE设计方案 朋友圈的设计及实现 几个大型网站的Feeds(Timeline)设计简单对比","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"查找附近的人","date":"2019-01-04T11:46:12.000Z","path":"2019/01/04/查找附近的人/","text":"GeoHash比较原始的方法，简单方便 Mysql计算公式 12C = sin(MLatA)*sin(MLatB)*cos(MLonA-MLonB) + cos(MLatA)*cos(MLatB)Distance = R*Arccos(C)*Pi/180 在经纬度小节中我们了解了两个公式用来计算两个位置之间的距离, 该小节我们以测试数据说明如何实现.测试需要的表结构和数据: 1234567891011121314151617表结构:CREATE TABLE `geotest` ( `userid` int(10) NOT NULL, `longitude` decimal(9,6) NOT NULL, `latitude` decimal(9,6) NOT NULL, `create_time` datetime DEFAULT NULL, UNIQUE KEY `unq_uid` (`userid`), KEY `idx_lat_lng` (`longitude`,`latitude`)) ENGINE=InnoDB DEFAULT CHARSET=utf8测试数据:insert geotest values(10000, 116.417480, 40.003033, now());insert geotest values(10001, 116.437480, 40.004033, now());insert geotest values(10002, 116.457480, 40.005033, now());insert geotest values(10003, 116.477480, 40.006033, now());............ 第一种公式中, google 为我们介绍了如何使用 sql 来获取附近的点, 如下所示, 我们选用 6371km 作为地球的半径,根据上述小节的计算公式推断: 12C = sin(MLatA)*sin(MLatB)*cos(MLonA-MLonB) + cos(MLatA)*cos(MLatB)Distance = R*Arccos(C)*Pi/180 google 地图的计算公式可以参考 geo_search 两个位置之间的距离则可以换算成以下公式: 1R*arccos( cos( radians(latA)*cos( radians(latB) ) * cos( radians(lonA - lonB) )) + sin( radians(latA)*cos(latB) )) radians 函数计算出相应的弧度信息, 得到下面的 sql: 1234567891011121314SELECT user_id, ( 6371 * acos ( cos ( radians(40.003033) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(116.417481) ) + sin ( radians(40.003033) ) * sin( radians( latitude ) ) ) ) AS distanceFROM geotestHAVING distance &lt; 1ORDER BY distanceLIMIT 0 , 20; 上面的 sql 从 geotest 中从 geotest 表中获取到经度(116.417481) 和纬度(40.003033) 位置附近 1km 所有的user_id 信息.观察这个 sql, 可以预见到在表数据较大的时候仅建立复合索引 idx_lat_lng 肯定会遇到性能瓶颈, 因为每行记录都需要做相关的运算, 才能跑出最后的结果. 所以要提高该 sql 的性能就需要尽量过滤不需要的 longitude 和 latitude 两列的值. 参考 geo_search 和 fastest-way-to-find-distance, 在近距离的情况下我们可以认为当前区域内的所有位置都在一个平面内, 虽然有点误差, 但是比起地球这么大的椭球, 我们完全可以忽略其中的误差. 以经纬度来讲, 1 纬度约等于 69 英里, 大约 111044.736 米, 其中的换算公式为: 121°latitude ~= 69 miles1°longitude ~= cos(latitude)*69 miles 所以对于位置信息(lng, lat), 我们可以计算出以其为中心周边指定距离的四个点, 如下图所示: 1234567+-------------+| || || + || || |+-------------+ 计算公式如下: 1234lng1 = lon - dist/abs(cos(radians(lat))*69)lng2 = lon + dist/abs(cos(radians(lat))*69)lat1 = lat - (dist/69);lat2 = lat + (dist/69); 四个点的坐标就分别为 (lng1, lat1), (lng1, lat2), (lng2, lat1), (lng2, lat2), 所以存在于该四个点组成的平面之间的点即可以被认为在(lng, lat) 的 dist 距离内. 基于上述的规则, 修改 sql 为以下: 12345678910111213141516SELECT user_id, ( 6371 * acos ( cos ( radians(40.003033) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(116.417481) ) + sin ( radians(40.003033) ) * sin( radians( latitude ) ) ) ) AS distanceFROM geotestWHERE longitude BETWEEN lng1 AND lng2AND latitude BETWEEN lat1 AND lat2HAVING distance &lt; 1ORDER BY distanceLIMIT 0 , 20; 这样就能很好的使用索引, 如果还想增加超时设置, 可以在 sql 里加上 create_time 条件进行过滤, 比如只查找最近一天的附近的用户. 另外开发者也可以结合使用 sphinx 或 elasticsearch 得到更好的性能. 下面为根据上面介绍的规则整理成存储过程, 方便开发者调用访问. 这里我们将地球半径的公里数转换为米即为 6371392.89m, 69英里则转为 111044.736m, 如下存储过程返回 user_id 和 距离(米): 12345678910111213141516171819202122232425262728293031DELIMITER $$drop procedure if exists geo_dist$$create procedure geo_dist(IN lng decimal(9, 6), IN lat decimal(9, 6), IN dist int)begin declare lng1 decimal(9, 6); declare lng2 decimal(16, 13); declare lat1 decimal(9, 6); declare lat1 decimal(16, 13); -- calculate lng and lat for the rectangle, in meters unit set lng1 = lng - dist/abs(cos(radians(lat))*111044.736); set lng2 = lng + dist/abs(cos(radians(lat))*111044.736); set lat1 = lat - (dist/111044.736); set lat2 = lat + (dist/111044.736); -- run the query select user_id, round(( 6371392.89 * acos ( cos ( radians(lat) ) * cos( radians( latitude ) ) * cos( radians( longitude ) - radians(lng) ) + sin ( radians(lat) ) * sin( radians( latitude ) ) ) ), 0) AS distance from user_position where lng between lng1 and lng2 and lat between lat1 and lat2 having distance &lt; dist ORDER BY distance LIMIT 0 , 20;END$$DELIMITER ; 运行存储过程, 取出该经纬度下附近 5km 的用户和距离(m): 1234567891011mysql &gt; call geo_dist(116.4174800000000, 40.0030330000000, 5000);+---------+----------+| user_id | distance |+---------+----------+| 10000 | 0 || 10001 | 1707 || 10002 | 3414 |+---------+----------+3 rows in set (0.00 sec)Query OK, 0 rows affected (0.01 sec) 10001 用户和指定的经纬度距离为1707米, 我们在 redis 3.2 版本中进行简单测试, 可以看到结果都很相近: 123456127.0.0.1:6380&gt; geoadd tttt 116.417480 40.003033 t1(integer) 0127.0.0.1:6380&gt; geoadd tttt 116.437481 40.004034 t2(integer) 0127.0.0.1:6380&gt; GEODIST tttt t1 t2&quot;1707.5093&quot; mongodb创建位置索引 参考 使用 MySQL 实现搜索附近的人 GeoHash算法学习讲解、解析及原理分析","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"},{"name":"mongodb","slug":"mongodb","permalink":"http://wumuwumu.github.io/tags/mongodb/"},{"name":"mysql","slug":"mysql","permalink":"http://wumuwumu.github.io/tags/mysql/"}]},{"title":"springboot-mongodb使用","date":"2019-01-04T01:43:06.000Z","path":"2019/01/04/springboot-mongodb使用/","text":"基本注解 @id @Document @DBRef $Indexed @CompoundIndex @GenSpatialIndexed @Transient @PersistenceConstructor","tags":[{"name":"springboot","slug":"springboot","permalink":"http://wumuwumu.github.io/tags/springboot/"},{"name":"mongodb","slug":"mongodb","permalink":"http://wumuwumu.github.io/tags/mongodb/"}]},{"title":"cordova打包vue","date":"2019-01-02T09:12:09.000Z","path":"2019/01/02/cordova打包vue/","text":"https://segmentfault.com/a/1190000013159076","tags":[{"name":"vue","slug":"vue","permalink":"http://wumuwumu.github.io/tags/vue/"}]},{"title":"Oracle表管理","date":"2018-12-29T13:45:47.000Z","path":"2018/12/29/oracle/Oracle表管理/","text":"数据类型123456789101112131415## 字符型char 定长，后面空格补全varchar2() 变长clob 字符型大对象## 数字类型numbernumber(5，2) 标识5位有效数，2位小数-999.99-999.99number(5) 5位整数## 日期类型datetimestramp## 图片blob 二进制4g,为了安全可以放入数据库 表操作12345678910create table table_name()drop table table_name;rename table_name to other_table_name;alter table table_name add ...;alter table table_name modify ...;alter table table_name drop column ...;","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wumuwumu.github.io/tags/oracle/"}]},{"title":"Oracle基本管理","date":"2018-12-29T12:37:37.000Z","path":"2018/12/29/oracle/Oracle基本管理/","text":"用户管理12345678910111213141516171819202122232425## 创建用户create user test identified by test;show user;## 删除用户delete test (cascade);## 修改用户alter user test identified by wumu;alter user test expire;## 用户口令## 密码输错三次就密码锁定2天create profile lock_account limit failed_login_attempts 3 password_lock_time 2;alter user tea profile lock_account;## 解锁alter user tea account unlock;## 每10天需要修改密码，宽限期为两天create profile myprofile limit password_life_time 10 password_grace_time 2;alter user tea profile myprofile;## 口令10天后可以重用create profile password_history limit password_lift_time 10 password_grace_time 2 password_reuse_time 10## 撤销profiledrop profile my_profile CASCADE； 权限管理12345678910111213141516171819202122232425## 授权grant system_privilege|all privileges to &#123;user identified by password |role|&#125;[with admin option]grant object_privileage | Allon schema.objectto user | role[with admin option][with the grant any object]grant select on test to wumu with grant option;grant connect tp wumu with admin option;## create session 用于登录## dba 管路员## resource 可以建表## desc table_name## 撤销权限## 如果授权者的权限被撤回，那么它的被授予者也会失去相关的权限invoke system_privilege from user|roleinvoke object_privilege|All on scheme.object from user|role [cascade contraints]## 查询权限## 系统权限放在DBA_SYS_PRIVS## 对象权限放在数据字典DBA_TAB_PRIVS","tags":[{"name":"oracle","slug":"oracle","permalink":"http://wumuwumu.github.io/tags/oracle/"}]},{"title":"Vue插件开发","date":"2018-12-17T12:52:34.000Z","path":"2018/12/17/Vue插件开发/","text":"基本结构插件的功能包括全局方法和属性、指令、mixin、实例方法。插件都有一个install方法，第一个参数是Vue，第二个参数是options。 1234567891011121314151617181920MyPlugin.install = function (Vue, options) &#123; Vue.myGlobalMethod = function () &#123; // 1. 添加全局方法或属性，如: vue-custom-element // 逻辑... &#125; Vue.directive('my-directive', &#123; // 2. 添加全局资源：指令/过滤器/过渡等，如 vue-touch bind (el, binding, vnode, oldVnode) &#123; // 逻辑... &#125; ... &#125;) Vue.mixin(&#123; created: function () &#123; // 3. 通过全局 mixin方法添加一些组件选项，如: vuex // 逻辑... &#125; ... &#125;) Vue.prototype.$myMethod = function (options) &#123; // 4. 添加实例方法，通过把它们添加到 Vue.prototype 上实现 // 逻辑... &#125;&#125; vue-toast","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"},{"name":"vue","slug":"vue","permalink":"http://wumuwumu.github.io/tags/vue/"}]},{"title":"JSqlParser教程","date":"2018-12-05T13:58:31.000Z","path":"2018/12/05/JSqlParser教程/","text":"解析获取表名12345//获取所有使用过的表Statement statement = CCJSqlParserUtil.parse(\"SELECT * FROM MY_TABLE1\"); Select selectStatement = (Select) statement; TablesNamesFinder tablesNamesFinder = new TablesNamesFinder(); List&lt;String&gt; tableList = tablesNamesFinder.getTableList(selectStatement); 应用别名1234// SELECT a AS A1, b AS A2, c AS A3 FROM testSelect select = (Select) CCJSqlParserUtil.parse(\"select a,b,c from test\"); final AddAliasesVisitor instance = new AddAliasesVisitor(); select.getSelectBody().accept(instance); 添加一列或者表达式123// SELECT a, b FROM mytableSelect select = (Select) CCJSqlParserUtil.parse(\"select a from mytable\");SelectUtils.addExpression(select, new Column(\"b\")); 添加where语句新建where12345678Select select = (Select) CCJSqlParserUtil.parse(\"select name from user\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); if (plainSelect.getWhere() == null) &#123; EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(\"id\")); equalsTo.setRightExpression(new LongValue(1000L)); plainSelect.setWhere(equalsTo); &#125; 添加where12345678910111213Select select = (Select) CCJSqlParserUtil.parse(\"select name from user where id = 1000\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的查询条件表达式 EqualsTo equalsTo = new EqualsTo(); equalsTo.setLeftExpression(new Column(\"name\")); equalsTo.setRightExpression(new StringValue(\"'张三'\")); // 用and链接条件 AndExpression and = new AndExpression(where, equalsTo); // 设置新的where条件 plainSelect.setWhere(and); 添加null12345678910111213Select select = (Select) CCJSqlParserUtil.parse(\"select name from user where id = 1000\"); PlainSelect plainSelect = (PlainSelect) select.getSelectBody(); // 原where表达式 Expression where = plainSelect.getWhere(); // 新增的null判断条件 IsNullExpression isNullExpression = new IsNullExpression(); isNullExpression.setLeftExpression(new Column(\"name\")); isNullExpression.setNot(true); // 用and链接条件 AndExpression and = new AndExpression(where, isNullExpression); // 设置新的where条件 plainSelect.setWhere(and); 生成扩展插入123456789101112131415161718192021222324// INSERT INTO mytable (col1) VALUES (1)// INSERT INTO mytable (col1, col2) VALUES (1, 5)// INSERT INTO mytable (col1, col2, col3) VALUES (1, 5, 10)Insert insert = (Insert) CCJSqlParserUtil.parse(\"insert into mytable (col1) values (1)\"); System.out.println(insert.toString()); insert.getColumns().add(new Column(\"col2\")); insert.getItemsList().accept(new ItemsListVisitor() &#123; public void visit(SubSelect subSelect) &#123; throw new UnsupportedOperationException(\"Not supported yet.\"); &#125; public void visit(ExpressionList expressionList) &#123; expressionList.getExpressions().add(new LongValue(5)); &#125; public void visit(MultiExpressionList multiExprList) &#123; throw new UnsupportedOperationException(\"Not supported yet.\"); &#125; &#125;); System.out.println(insert.toString()); insert.getColumns().add(new Column(\"col3\")); ((ExpressionList) insert.getItemsList()).getExpressions().add(new LongValue(10)); 建立select12345Select select = SelectUtils.buildSelectFromTable(new Table(\"mytable\"));Select select = SelectUtils.buildSelectFromTableAndExpressions(new Table(\"mytable\"), new Column(\"a\"), new Column(\"b\"));Select select = SelectUtils.buildSelectFromTableAndExpressions(new Table(\"mytable\"), \"a+b\", \"test\"); 代替字符串的值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677String sql =\"SELECT NAME, ADDRESS, COL1 FROM USER WHERE SSN IN ('11111111111111', '22222222222222');\";Select select = (Select) CCJSqlParserUtil.parse(sql);//Start of value modificationStringBuilder buffer = new StringBuilder();ExpressionDeParser expressionDeParser = new ExpressionDeParser() &#123; @Override public void visit(StringValue stringValue) &#123; this.getBuffer().append(\"XXXX\"); &#125; &#125;;SelectDeParser deparser = new SelectDeParser(expressionDeParser,buffer );expressionDeParser.setSelectVisitor(deparser);expressionDeParser.setBuffer(buffer);select.getSelectBody().accept(deparser);//End of value modificationSystem.out.println(buffer.toString());//Result is: SELECT NAME, ADDRESS, COL1 FROM USER WHERE SSN IN (XXXX, XXXX)import net.sf.jsqlparser.JSQLParserException;import net.sf.jsqlparser.expression.LongValue;import net.sf.jsqlparser.expression.StringValue;import net.sf.jsqlparser.parser.CCJSqlParserUtil;import net.sf.jsqlparser.statement.Statement;import net.sf.jsqlparser.util.deparser.ExpressionDeParser;import net.sf.jsqlparser.util.deparser.SelectDeParser;import net.sf.jsqlparser.util.deparser.StatementDeParser;public class ReplaceColumnValues &#123; static class ReplaceColumnAndLongValues extends ExpressionDeParser &#123; @Override public void visit(StringValue stringValue) &#123; this.getBuffer().append(\"?\"); &#125; @Override public void visit(LongValue longValue) &#123; this.getBuffer().append(\"?\"); &#125; &#125; public static String cleanStatement(String sql) throws JSQLParserException &#123; StringBuilder buffer = new StringBuilder(); ExpressionDeParser expr = new ReplaceColumnAndLongValues(); SelectDeParser selectDeparser = new SelectDeParser(expr, buffer); expr.setSelectVisitor(selectDeparser); expr.setBuffer(buffer); StatementDeParser stmtDeparser = new StatementDeParser(expr, selectDeparser, buffer); Statement stmt = CCJSqlParserUtil.parse(sql); stmt.accept(stmtDeparser); return stmtDeparser.getBuffer().toString(); &#125; public static void main(String[] args) throws JSQLParserException &#123; System.out.println(cleanStatement(\"SELECT 'abc', 5 FROM mytable WHERE col='test'\")); System.out.println(cleanStatement(\"UPDATE table1 A SET A.columna = 'XXX' WHERE A.cod_table = 'YYY'\")); System.out.println(cleanStatement(\"INSERT INTO example (num, name, address, tel) VALUES (1, 'name', 'test ', '1234-1234')\")); System.out.println(cleanStatement(\"DELETE FROM table1 where col=5 and col2=4\")); &#125;&#125;/*SELECT ?, ? FROM mytable WHERE col = ?UPDATE table1 A SET A.columna = ? WHERE A.cod_table = ?INSERT INTO example (num, name, address, tel) VALUES (?, ?, ?, ?)DELETE FROM table1 WHERE col = ? AND col2 = ?*/ 参考 https://github.com/JSQLParser/JSqlParser/wiki","tags":[{"name":"java","slug":"java","permalink":"http://wumuwumu.github.io/tags/java/"}]},{"title":"react入门教程","date":"2018-12-05T13:56:22.000Z","path":"2018/12/05/react入门教程/","text":"webpack4初始化12cnpm i -D webpackcnpm i -D webpack-cli //相关的命令 相应包的安装 react 专门用于创建组件和虚拟DOM，同事组件的生命周期在这个包中。 react-dom 专门进行dom操作的，最主要的应用场景，就是ReactDom.render() babel babel-node 一个命令行工具 babel-register 可以实现动态转换 babel-core 核心包 babel-preset-env 一个套餐 jsx使用安装babel插件123cnpm i babel-core babel-loader babel-plugin-transform-runtime -Dcnpm i babel-preset-env babel-preset-stage-0 -Dcnpm i babel-preset-react -D 添加.babelrc配置文件1234&#123; &quot;presets&quot;:[&quot;env&quot;,&quot;stage-0&quot;,&quot;react&quot;], &quot;plugins&quot;:[&quot;transform-runtime&quot;]&#125; ##添加babel-loader配置项 12345module：&#123; rules:[ &#123;test:/\\.js|jsx/,use:&apos;babel-loader&apos;,exclude:/node_modules/&#125; ]&#125;","tags":[{"name":"react","slug":"react","permalink":"http://wumuwumu.github.io/tags/react/"}]},{"title":"nginx配置","date":"2018-12-05T13:47:32.000Z","path":"2018/12/05/nginx配置/","text":"配置web服务器1234567891011server &#123; listen 80; server_name api.lufficc.com *.lufficc.com; location /images/ &#123; root /data; &#125; location / &#123; proxy_pass https://lufficc.com; &#125;&#125; 反向代理1234567server&#123; listen 80; server_name search.lufficc.com; location / &#123; proxy_pass https://www.baidu.com; &#125;&#125; 参考 https://lufficc.com/blog/configure-nginx-as-a-web-server https://blog.csdn.net/hj7jay/article/details/53905943 http://www.nginx.cn/76.html","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"},{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"centos7修改网卡","date":"2018-12-05T13:40:23.000Z","path":"2018/12/05/centos7修改网卡/","text":"修改mac使用virtualbox导入一个虚拟机时mac地址是一样的，此时需要修改。 修改mac地址直接在virtualBox的setting&gt;network配置中进行修改。 修改网卡名称修改网卡的配置文件123vim /etc/sysconfig/network-scripts/ifcfg-eno16777736 //修改NAME，DEVICE 成希望的（不要加ifcfg）mv ifcfg-eno16777736 ifcfg-eth0 //修改配置文件的名字 禁用可预测命名规则1vim /etc/default/grub 添加内核参数： net.ifnames=0 biosdevname=0 12345678[root@ansheng network-scripts]# vi /etc/default/grubGRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=savedGRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet net.ifnames=0 biosdevname=0&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot; 用 grub2-mkconfig 命令重新生成GRUB配置并更新内核1234567[root@ansheng network-scripts]# grub2-mkconfig -o /boot/grub2/grub.cfgGenerating grub configuration file ...Found linux image: /boot/vmlinuz-3.10.0-327.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-327.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-4dd6b54f74c94bff9e92c61d669fc195Found initrd image: /boot/initramfs-0-rescue-4dd6b54f74c94bff9e92c61d669fc195.imgdone 重启系统","tags":[{"name":"linux","slug":"linux","permalink":"http://wumuwumu.github.io/tags/linux/"}]},{"title":"nvc-server安装","date":"2018-12-05T13:39:00.000Z","path":"2018/12/05/nvc-server安装/","text":"centos 安装 vnc server没有实现多用户配置 1234567891011121314151617181920yum install tigervnc-server -ycp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service## 然后打开这个配置文件/etc/systemd/system/vncserver@:1.service替换掉默认用户名 ## ExecStart=/sbin/runuser -l &lt;USER&gt; -c &quot;/usr/bin/vncserver %i&quot;## PIDFile=/home/&lt;USER&gt;/.vnc/%H%i.pid## 这里我直接用root 用户登录，所以我替换成ExecStart=/sbin/runuser -l root -c &quot;/usr/bin/vncserver %i&quot;PIDFile=/root/.vnc/%H%i.pid## 如果是其他用户的话比如linoxide替换如下ExecStart=/sbin/runuser -l linoxide -c &quot;/usr/bin/vncserver %i&quot;PIDFile=/home/linoxide/.vnc/%H%i.pidsystemctl daemon-reloadvncpasswd## 开放端口## 重启服务systemctl enable vncserver@:1.servicesystemctl start vncserver@:1.service ubuntu 安装 vnc viewer1sudo dpkg -i VNC-Viewer-6.17.1113-Linux-x64.deb 参考 https://my.oschina.net/huhaoren/blog/497394","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"VirtualBox磁盘扩容","date":"2018-12-05T13:36:46.000Z","path":"2018/12/05/VirtualBox磁盘扩容/","text":"扩展磁盘文件VDI1VBoxManage modifyhd centos.vdi --resize 16000 # 单位M VMDK123VBoxManage clonehd &quot;centos.vmdk&quot; &quot;centos.vdi&quot; --format vdi # vmdk是转换前的文件，vdi是转换之后的文件VBoxManage modifyhd &quot;centos.vdi&quot; --resize 16000 # 这里的单位是MVBoxManage clonehd &quot;centos.vdi&quot; &quot;resized.vmdk&quot; --format vmdk #可以再转回来 使用克隆本人在使用的时候，前面两种方式不能实现，采用第三种方式 12VBoxManage createhd -filename centos7-main-64g -size 65536 -format VDI -variant Standard # 创建一个新的磁盘，磁盘大小为想要的大小VBoxManage clonemedium ../centos7-main\\ Clone/centos7-main\\ Clone.vdi centos7-main-64g.vdi --existing # 将原有的磁盘复制到新磁盘上 磁盘扩容这里可以使用gparted进行磁盘的扩容 下载gparted-live镜像 设置iso镜像开机启动 进行分区的修改 LVM扩容如果你没有使用逻辑卷就可以跳过这节。如果使用逻辑卷也可以通过添加新磁盘的形式对文件系统进行扩容，这种方式更加简单方便。 创建PE、VG扩展LV12sudo vgextend VolGroup /dev/sda4 # 通过新卷的方式扩展到卷组lvresize -l +122 /dev/centos/root # 直接扩容 刷新逻辑分区容量1xfs_growfs /devices/centos/root # resize2fs是不能成功的","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"lorawan协议（中文版）","date":"2018-12-05T13:34:09.000Z","path":"2018/12/05/lorawan协议（中文版）/","text":"介绍网关和服务器之间的协议是有目的的非常基本的，仅用于演示目的，或用于私有和可靠的网络。 这里没有网关或服务器的认证，并且确认仅用于网络质量评估，而不是 纠正UDP数据报丢失（无重试）。 系统原理和相关定义1234567891011121314151617 ((( Y ))) | |+ - -|- - - - - - - - - - - - - + xxxxxxxxxxxx +--------+| +--+-----------+ +------+ | xx x x xxx | || | | | | | xx Internet xx | || | Concentrator |&lt;---&gt;| Host |&lt;-------xx or xx--------&gt;| || | | SPI | | | xx Intranet xx | Server || +--------------+ +------+ | xxxx x xxxx | || ^ ^ | xxxxxxxx | || | PPS +-------+ NMEA | | | || +-----| GPS |-------+ | +--------+| | (opt) | || +-------+ || || Gateway |+- - - - - - - - - - - - - - - -+ 网关：无线电RX / TX板，基于Semtech多通道调制解调器（SX130x），收发器（SX135x）和/或低功耗独立调制解调器（SX127x）。 主机：运行包转发器的嵌入式计算机。通过SPI链路驱动集中器。 GPS：具有“每秒1脉冲”的GNSS（GPS，伽利略，GLONASS等）接收器 输出和到主机的串行链接，以发送包含时间和地理坐标数据的NMEA帧。可选的。 网关：由至少一个无线电集中器，主机，一些组成的设备网络连接到互联网或专用网络（以太网，3G，Wifi，微波链路），以及可选的GPS接收器进行同步。 服务器：一种抽象计算机，它将处理由网关接收和转发的RF数据包，并发出RF数据包以响应网关必须发出的数据包。 假设网关可以在NAT后面或防火墙停止任何传入连接。 假设服务器具有静态IP地址（或通过DNS服务可解决的地址），并且能够接收特定端口上的传入连接。 上行协议3.1 时序图 12345678910111213141516+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | -----------------------------------\\ | |-| When 1-N RF packets are received | | | ------------------------------------ | | | | PUSH_DATA (token X, GW MAC, JSON payload) | |-------------------------------------------------------------&gt;| | | | PUSH_ACK (token X) | |&lt;-------------------------------------------------------------| | ------------------------------\\ | | | process packets *after* ack |-| | ------------------------------- | | | PUSH_DATA 包网关使用该数据包类型主要是将所接收的RF分组和相关联的元数据转发到服务器。 字节 功能 0 协议版本2 1-2 随机凭证 3 PUSH_DATA标识0x00 4-11 网关唯一标识（MAC地址） 12-结束 JSON对象，看第4章 PUSH_ACK包服务器使用该数据包类型立即确认收到的所有PUSH_DATA数据包。 字节 功能 0 协议版本2 1-2 与PUSH_DATA包中相同的凭证，用于确认 3 PUSH_ACK标识0x01 上行JSON数据结构根对象包含名为&quot;rxpk&quot;的数组： 123&#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...]&#125; 该数组包含至少一个JSON对象，每个对象包含一个RF数据包以及包含以下字段的关联元数据： 名称 类别 功能 time string UTC time of pkt RX, us precision, ISO 8601 ‘compact’ format tmst number Internal timestamp of “RX finished” event (32b unsigned) freq number RX central frequency in MHz (unsigned float, Hz precision) chan number Concentrator “IF” channel used for RX (unsigned integer) rfch number Concentrator “RF chain” used for RX (unsigned integer) stat number CRC status: 1 = OK, -1 = fail, 0 = no CRC modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier rssi number RSSI in dBm (signed integer, 1 dB precision) lsnr number Lora SNR ratio in dB (signed float, 0.1 dB precision) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padded 示例（为了便于阅读而添加了空格，缩进和换行符）： 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123;&quot;rxpk&quot;:[ &#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.528002Z&quot;, &quot;tmst&quot;:3512348611, &quot;chan&quot;:2, &quot;rfch&quot;:0, &quot;freq&quot;:866.349812, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF7BW125&quot;, &quot;codr&quot;:&quot;4/6&quot;, &quot;rssi&quot;:-35, &quot;lsnr&quot;:5.1, &quot;size&quot;:32, &quot;data&quot;:&quot;-DS4CGaDCdG+48eJNM3Vai-zDpsR71Pn9CPA9uCON84&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.530974Z&quot;, &quot;tmst&quot;:3512348514, &quot;chan&quot;:9, &quot;rfch&quot;:1, &quot;freq&quot;:869.1, &quot;stat&quot;:1, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;rssi&quot;:-75, &quot;size&quot;:16, &quot;data&quot;:&quot;VEVTVF9QQUNLRVRfMTIzNA==&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.532038Z&quot;, &quot;tmst&quot;:3316387610, &quot;chan&quot;:0, &quot;rfch&quot;:0, &quot;freq&quot;:863.00981, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF10BW125&quot;, &quot;codr&quot;:&quot;4/7&quot;, &quot;rssi&quot;:-38, &quot;lsnr&quot;:5.5, &quot;size&quot;:32, &quot;data&quot;:&quot;ysgRl452xNLep9S1NTIg2lomKDxUgn3DJ7DE+b00Ass&quot; &#125;]&#125; 根对象还可以包含名为&quot;stat&quot;的对象： 1234&#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...], &quot;stat&quot;:&#123;...&#125;&#125; 数据包可能不包含&quot;rxpk&quot;数组而是“stat”对象。 123&#123; &quot;stat&quot;:&#123;...&#125;&#125; 该对象包含网关的状态，包含以下字段： 名称 类型 功能 time string UTC ‘system’ time of the gateway, ISO 8601 ‘expanded’ format lati number GPS latitude of the gateway in degree (float, N is +) long number GPS latitude of the gateway in degree (float, E is +) alti number GPS altitude of the gateway in meter RX (integer) rxnb number Number of radio packets received (unsigned integer) rxok number Number of radio packets received with a valid PHY CRC rxfw number Number of radio packets forwarded (unsigned integer) ackr number Percentage of upstream datagrams that were acknowledged dwnb number Number of downlink datagrams received (unsigned integer) txnb number Number of packets emitted (unsigned integer) 示例（为了便于阅读而添加了空格，缩进和换行符）： 123456789101112&#123;&quot;stat&quot;:&#123; &quot;time&quot;:&quot;2014-01-12 08:59:28 GMT&quot;, &quot;lati&quot;:46.24000, &quot;long&quot;:3.25230, &quot;alti&quot;:145, &quot;rxnb&quot;:2, &quot;rxok&quot;:2, &quot;rxfw&quot;:2, &quot;ackr&quot;:100.0, &quot;dwnb&quot;:2, &quot;txnb&quot;:2&#125;&#125; 下行协议时序图1234567891011121314151617181920212223242526+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | -----------------------------------\\ | |-| Every N seconds (keepalive time) | | | ------------------------------------ | | | | PULL_DATA (token Y, MAC@) | |-------------------------------------------------------------&gt;| | | | PULL_ACK (token Y) | |&lt;-------------------------------------------------------------| | |+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | ------------------------------------------------------\\ | | | Anytime after first PULL_DATA for each packet to TX |-| | ------------------------------------------------------- | | | | PULL_RESP (token Z, JSON payload) | |&lt;-------------------------------------------------------------| | | | TX_ACK (token Z, JSON payload) | |-------------------------------------------------------------&gt;| PULL_DATA包网关使用该数据包类型来轮询来自服务器的数据。 此数据交换由网关初始化，因为如果网关位于NAT后面，服务器可能无法将数据包发送到网关。 当网关初始化交换机时，将打开通向服务器的网络路由，并允许数据包在两个方向上流动。 网关必须定期发送PULL_DATA数据包，以确保网络路由保持打开状态，以便服务器随时使用。 Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_DATA identifier 0x02 4-11 Gateway unique identifier (MAC address) PULL_ACK 包服务器使用该数据包类型来确认网络路由是否已打开，以及服务器是否可以随时发送PULL_RESP数据包。 Bytes Function 0 protocol version = 2 1-2 same token as the PULL_DATA packet to acknowledge 3 PULL_ACK identifier 0x04 PULL_RESP 包服务器使用该数据包类型来发送必须由网关发出的RF数据包和相关元数据。 Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_RESP identifier 0x03 4-end JSON object, starting with {, ending with }, see section 6 TX_ACK 包网关使用该分组类型向服务器发送反馈，以通知网关是否已接受或拒绝下行链路请求。 数据报可以选项包含一个JSON字符串，以提供有关acknoledge的更多详细信息。 如果没有JSON（空字符串），这意味着没有发生错误。 Bytes Function 0 protocol version = 2 1-2 same token as the PULL_RESP packet to acknowledge 3 TX_ACK identifier 0x05 4-11 Gateway unique identifier (MAC address) 12-end [optional] JSON object, starting with {, ending with }, see section 6 下行JSON数据结构 PULL_RESP数据包的根对象必须包含名为“txpk”的对象： 123&#123; &quot;txpk&quot;: &#123;...&#125;&#125; 该对象包含要发出的RF数据包以及与以下字段相关联的元数据： Name Type Function imme bool Send packet immediately (will ignore tmst &amp; time) tmst number Send packet on a certain timestamp value (will ignore time) time string Send packet at a certain time (GPS synchronization required) freq number TX central frequency in MHz (unsigned float, Hz precision) rfch number Concentrator “RF chain” used for TX (unsigned integer) powe number TX output power in dBm (unsigned integer, dBm precision) modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier fdev number FSK frequency deviation (unsigned integer, in Hz) ipol bool Lora modulation polarization inversion prea number RF preamble size (unsigned integer) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padding optional ncrc bool If true, disable the CRC of the physical layer (optional) 大多数字段都是可选的。如果省略字段，将使用默认参数。 示例（为便于阅读而添加了空格，缩进和换行符）： 1234567891011121314151617181920212223&#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:864.123456, &quot;rfch&quot;:0, &quot;powe&quot;:14, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF11BW125&quot;, &quot;codr&quot;:&quot;4/6&quot;, &quot;ipol&quot;:false, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot;&#125;&#125;&#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:861.3, &quot;rfch&quot;:0, &quot;powe&quot;:12, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;fdev&quot;:3000, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot;&#125;&#125; TX_ACK数据包的根对象必须包含名为“txpk_ack”的对象： 123&#123; &quot;txpk_ack&quot;: &#123;...&#125;&#125; 该对象包含有关相关PULL_RESP数据包的状态信息。 Name Type Function error string Indication about success or type of failure that occured for downlink request. 可能的错误有： Value Definition NONE Packet has been programmed for downlink TOO_LATE Rejected because it was already too late to program this packet for downlink TOO_EARLY Rejected because downlink packet timestamp is too much in advance COLLISION_PACKET Rejected because there was already a packet programmed in requested timeframe COLLISION_BEACON Rejected because there was already a beacon planned in requested timeframe TX_FREQ Rejected because requested frequency is not supported by TX RF chain TX_POWER Rejected because requested power is not supported by gateway GPS_UNLOCKED Rejected because GPS is unlocked, so GPS timestamp cannot be used 示例（为便于阅读而添加了空格，缩进和换行符）： 123&#123;&quot;txpk_ack&quot;:&#123; &quot;error&quot;:&quot;COLLISION_PACKET&quot;&#125;&#125;","tags":[{"name":"lorawan","slug":"lorawan","permalink":"http://wumuwumu.github.io/tags/lorawan/"}]},{"title":"lorawan协议","date":"2018-12-05T13:32:24.000Z","path":"2018/12/05/lorawan协议/","text":"Introduction The protocol between the gateway and the server is purposefully very basic and for demonstration purpose only, or for use on private and reliable networks. There is no authentication of the gateway or the server, and the acknowledges are only used for network quality assessment, not to correct UDP datagrams losses (no retries). System schematic and definitions 1234567891011121314151617 ((( Y ))) | |+ - -|- - - - - - - - - - - - - + xxxxxxxxxxxx +--------+| +--+-----------+ +------+ | xx x x xxx | || | | | | | xx Internet xx | || | Concentrator |&lt;---&gt;| Host |&lt;-------xx or xx--------&gt;| || | | SPI | | | xx Intranet xx | Server || +--------------+ +------+ | xxxx x xxxx | || ^ ^ | xxxxxxxx | || | PPS +-------+ NMEA | | | || +-----| GPS |-------+ | +--------+| | (opt) | || +-------+ || || Gateway |+- - - - - - - - - - - - - - - -+ Concentrator: radio RX/TX board, based on Semtech multichannel modems (SX130x), transceivers (SX135x) and/or low-power stand-alone modems (SX127x). Host: embedded computer on which the packet forwarder is run. Drives the concentrator through a SPI link. GPS: GNSS (GPS, Galileo, GLONASS, etc) receiver with a “1 Pulse Per Second” output and a serial link to the host to send NMEA frames containing time and geographical coordinates data. Optional. Gateway: a device composed of at least one radio concentrator, a host, some network connection to the internet or a private network (Ethernet, 3G, Wifi, microwave link), and optionally a GPS receiver for synchronization. Server: an abstract computer that will process the RF packets received and forwarded by the gateway, and issue RF packets in response that the gateway will have to emit. It is assumed that the gateway can be behind a NAT or a firewall stopping any incoming connection. It is assumed that the server has an static IP address (or an address solvable through a DNS service) and is able to receive incoming connections on a specific port. Upstream protocol Sequence diagram12345678910111213141516+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | -----------------------------------\\ | |-| When 1-N RF packets are received | | | ------------------------------------ | | | | PUSH_DATA (token X, GW MAC, JSON payload) | |-------------------------------------------------------------&gt;| | | | PUSH_ACK (token X) | |&lt;-------------------------------------------------------------| | ------------------------------\\ | | | process packets *after* ack |-| | ------------------------------- | | | PUSH_DATA packetThat packet type is used by the gateway mainly to forward the RF packets received, and associated metadata, to the server. Bytes Function 0 protocol version = 2 1-2 random token 3 PUSH_DATA identifier 0x00 4-11 Gateway unique identifier (MAC address) 12-end JSON object, starting with {, ending with }, see section 4 PUSH_ACK packetThat packet type is used by the server to acknowledge immediately all the PUSH_DATA packets received. Bytes Function 0 protocol version = 2 1-2 same token as the PUSH_DATA packet to acknowledge 3 PUSH_ACK identifier 0x01 Upstream JSON data structure The root object can contain an array named “rxpk”: 123&#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...]&#125; That array contains at least one JSON object, each object contain a RF packet and associated metadata with the following fields: Name Type Function time string UTC time of pkt RX, us precision, ISO 8601 ‘compact’ format tmst number Internal timestamp of “RX finished” event (32b unsigned) freq number RX central frequency in MHz (unsigned float, Hz precision) chan number Concentrator “IF” channel used for RX (unsigned integer) rfch number Concentrator “RF chain” used for RX (unsigned integer) stat number CRC status: 1 = OK, -1 = fail, 0 = no CRC modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier rssi number RSSI in dBm (signed integer, 1 dB precision) lsnr number Lora SNR ratio in dB (signed float, 0.1 dB precision) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padded Example (white-spaces, indentation and newlines added for readability): 12345678910111213141516171819202122232425262728293031323334353637383940414243&#123;&quot;rxpk&quot;:[ &#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.528002Z&quot;, &quot;tmst&quot;:3512348611, &quot;chan&quot;:2, &quot;rfch&quot;:0, &quot;freq&quot;:866.349812, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF7BW125&quot;, &quot;codr&quot;:&quot;4/6&quot;, &quot;rssi&quot;:-35, &quot;lsnr&quot;:5.1, &quot;size&quot;:32, &quot;data&quot;:&quot;-DS4CGaDCdG+48eJNM3Vai-zDpsR71Pn9CPA9uCON84&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.530974Z&quot;, &quot;tmst&quot;:3512348514, &quot;chan&quot;:9, &quot;rfch&quot;:1, &quot;freq&quot;:869.1, &quot;stat&quot;:1, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;rssi&quot;:-75, &quot;size&quot;:16, &quot;data&quot;:&quot;VEVTVF9QQUNLRVRfMTIzNA==&quot; &#125;,&#123; &quot;time&quot;:&quot;2013-03-31T16:21:17.532038Z&quot;, &quot;tmst&quot;:3316387610, &quot;chan&quot;:0, &quot;rfch&quot;:0, &quot;freq&quot;:863.00981, &quot;stat&quot;:1, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF10BW125&quot;, &quot;codr&quot;:&quot;4/7&quot;, &quot;rssi&quot;:-38, &quot;lsnr&quot;:5.5, &quot;size&quot;:32, &quot;data&quot;:&quot;ysgRl452xNLep9S1NTIg2lomKDxUgn3DJ7DE+b00Ass&quot; &#125;]&#125; The root object can also contain an object named “stat” : 1234&#123; &quot;rxpk&quot;:[ &#123;...&#125;, ...], &quot;stat&quot;:&#123;...&#125;&#125; It is possible for a packet to contain no “rxpk” array but a “stat” object. 123&#123; &quot;stat&quot;:&#123;...&#125;&#125; That object contains the status of the gateway, with the following fields: Name Type Function time string UTC ‘system’ time of the gateway, ISO 8601 ‘expanded’ format lati number GPS latitude of the gateway in degree (float, N is +) long number GPS latitude of the gateway in degree (float, E is +) alti number GPS altitude of the gateway in meter RX (integer) rxnb number Number of radio packets received (unsigned integer) rxok number Number of radio packets received with a valid PHY CRC rxfw number Number of radio packets forwarded (unsigned integer) ackr number Percentage of upstream datagrams that were acknowledged dwnb number Number of downlink datagrams received (unsigned integer) txnb number Number of packets emitted (unsigned integer) Example (white-spaces, indentation and newlines added for readability): 123456789101112&#123;&quot;stat&quot;:&#123; &quot;time&quot;:&quot;2014-01-12 08:59:28 GMT&quot;, &quot;lati&quot;:46.24000, &quot;long&quot;:3.25230, &quot;alti&quot;:145, &quot;rxnb&quot;:2, &quot;rxok&quot;:2, &quot;rxfw&quot;:2, &quot;ackr&quot;:100.0, &quot;dwnb&quot;:2, &quot;txnb&quot;:2&#125;&#125; Downstream protocol Sequence diagram1234567891011121314151617181920212223242526+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | -----------------------------------\\ | |-| Every N seconds (keepalive time) | | | ------------------------------------ | | | | PULL_DATA (token Y, MAC@) | |-------------------------------------------------------------&gt;| | | | PULL_ACK (token Y) | |&lt;-------------------------------------------------------------| | |+---------+ +---------+| Gateway | | Server |+---------+ +---------+ | ------------------------------------------------------\\ | | | Anytime after first PULL_DATA for each packet to TX |-| | ------------------------------------------------------- | | | | PULL_RESP (token Z, JSON payload) | |&lt;-------------------------------------------------------------| | | | TX_ACK (token Z, JSON payload) | |-------------------------------------------------------------&gt;| PULL_DATA packetThat packet type is used by the gateway to poll data from the server. This data exchange is initialized by the gateway because it might be impossible for the server to send packets to the gateway if the gateway is behind a NAT. When the gateway initialize the exchange, the network route towards the server will open and will allow for packets to flow both directions. The gateway must periodically send PULL_DATA packets to be sure the network route stays open for the server to be used at any time. Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_DATA identifier 0x02 4-11 Gateway unique identifier (MAC address) PULL_ACK packetThat packet type is used by the server to confirm that the network route is open and that the server can send PULL_RESP packets at any time. Bytes Function 0 protocol version = 2 1-2 same token as the PULL_DATA packet to acknowledge 3 PULL_ACK identifier 0x04 PULL_RESP packetThat packet type is used by the server to send RF packets and associated metadata that will have to be emitted by the gateway. Bytes Function 0 protocol version = 2 1-2 random token 3 PULL_RESP identifier 0x03 4-end JSON object, starting with {, ending with }, see section 6 TX_ACK packetThat packet type is used by the gateway to send a feedback to the server to inform if a downlink request has been accepted or rejected by the gateway. The datagram may optionnaly contain a JSON string to give more details on acknoledge. If no JSON is present (empty string), this means than no error occured. Bytes Function 0 protocol version = 2 1-2 same token as the PULL_RESP packet to acknowledge 3 TX_ACK identifier 0x05 4-11 Gateway unique identifier (MAC address) 12-end [optional] JSON object, starting with {, ending with }, see section 6 Downstream JSON data structure The root object of PULL_RESP packet must contain an object named “txpk”: 123&#123; &quot;txpk&quot;: &#123;...&#125;&#125; That object contain a RF packet to be emitted and associated metadata with the following fields: Name Type Function imme bool Send packet immediately (will ignore tmst &amp; time) tmst number Send packet on a certain timestamp value (will ignore time) time string Send packet at a certain time (GPS synchronization required) freq number TX central frequency in MHz (unsigned float, Hz precision) rfch number Concentrator “RF chain” used for TX (unsigned integer) powe number TX output power in dBm (unsigned integer, dBm precision) modu string Modulation identifier “LORA” or “FSK” datr string LoRa datarate identifier (eg. SF12BW500) datr number FSK datarate (unsigned, in bits per second) codr string LoRa ECC coding rate identifier fdev number FSK frequency deviation (unsigned integer, in Hz) ipol bool Lora modulation polarization inversion prea number RF preamble size (unsigned integer) size number RF packet payload size in bytes (unsigned integer) data string Base64 encoded RF packet payload, padding optional ncrc bool If true, disable the CRC of the physical layer (optional) Most fields are optional. If a field is omitted, default parameters will be used. Examples (white-spaces, indentation and newlines added for readability): 1234567891011121314151617181920212223&#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:864.123456, &quot;rfch&quot;:0, &quot;powe&quot;:14, &quot;modu&quot;:&quot;LORA&quot;, &quot;datr&quot;:&quot;SF11BW125&quot;, &quot;codr&quot;:&quot;4/6&quot;, &quot;ipol&quot;:false, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot;&#125;&#125;&#123;&quot;txpk&quot;:&#123; &quot;imme&quot;:true, &quot;freq&quot;:861.3, &quot;rfch&quot;:0, &quot;powe&quot;:12, &quot;modu&quot;:&quot;FSK&quot;, &quot;datr&quot;:50000, &quot;fdev&quot;:3000, &quot;size&quot;:32, &quot;data&quot;:&quot;H3P3N2i9qc4yt7rK7ldqoeCVJGBybzPY5h1Dd7P7p8v&quot;&#125;&#125; The root object of TX_ACK packet must contain an object named “txpk_ack”: 123&#123; &quot;txpk_ack&quot;: &#123;...&#125;&#125; That object contain status information concerning the associated PULL_RESP packet. Name Type Function error string Indication about success or type of failure that occured for downlink request. The possible values of “error” field are: Value Definition NONE Packet has been programmed for downlink TOO_LATE Rejected because it was already too late to program this packet for downlink TOO_EARLY Rejected because downlink packet timestamp is too much in advance COLLISION_PACKET Rejected because there was already a packet programmed in requested timeframe COLLISION_BEACON Rejected because there was already a beacon planned in requested timeframe TX_FREQ Rejected because requested frequency is not supported by TX RF chain TX_POWER Rejected because requested power is not supported by gateway GPS_UNLOCKED Rejected because GPS is unlocked, so GPS timestamp cannot be used Examples (white-spaces, indentation and newlines added for readability): 123&#123;&quot;txpk_ack&quot;:&#123; &quot;error&quot;:&quot;COLLISION_PACKET&quot;&#125;&#125; Revisions v1.3 Added downlink feedback from gateway to server (PULL_RESP -&gt; TX_ACK) v1.2 Added value of FSK bitrate for upstream. Added parameters for FSK bitrate and frequency deviation for downstream. v1.1 Added syntax for status report JSON object on upstream. v1.0 Initial version.","tags":[{"name":"lorawan","slug":"lorawan","permalink":"http://wumuwumu.github.io/tags/lorawan/"}]},{"title":"let-us-encrypt证书","date":"2018-12-05T12:59:59.000Z","path":"2018/12/05/let-us-encrypt证书/","text":"基本知识为了实现通配符证书，Let’s Encrypt 对 ACME 协议的实现进行了升级，只有 v2 协议才能支持通配符证书。 客户在申请 Let’s Encrypt 证书的时候，需要校验域名的所有权，证明操作者有权利为该域名申请证书，目前支持三种验证方式： dns-01：给域名添加一个 DNS TXT 记录。 http-01：在域名对应的 Web 服务器下放置一个 HTTP well-known URL 资源文件。 tls-sni-01：在域名对应的 Web 服务器下放置一个 HTTPS well-known URL 资源文件。 而申请通配符证书，只能使用 dns-01 的方式 ACME v2 和 v1 协议是互相不兼容的，为了使用 v2 版本，客户端需要创建另外一个账户（代表客户端操作者），以 Certbot 客户端为例，大家可以查看： Enumerable Orders 和限制 安装12wget https://dl.eff.org/certbot-autochmod a+x ./certbot-auto 申请1./certbot-auto certonly -d *.newyingyong.cn --manual --preferred-challenges dns --server https://acme-v02.api.letsencrypt.org/directory certonly，表示安装模式，Certbot 有安装模式和验证模式两种类型的插件。 –manual 表示手动安装插件，Certbot 有很多插件，不同的插件都可以申请证书，用户可以根据需要自行选择 -d 为那些主机申请证书，如果是通配符，输入 *.newyingyong.cn（可以替换为你自己的域名） -preferred-challenges dns，使用 DNS 方式校验域名所有权 –server，Let’s Encrypt ACME v2 版本使用的服务器不同于 v1 版本，需要显示指定。 添加记录根据命令行提示，填写相关的内容，注意在添加记录的时候，要等到记录生效才确定。 123456789-------------------------------------------------------------------------------Please deploy a DNS TXT record under the name_acme-challenge.newyingyong.cn with the following value:2_8KBE_jXH8nYZ2unEViIbW52LhIqxkg6i9mcwsRvhQBefore continuing, verify the record is deployed.-------------------------------------------------------------------------------Press Enter to ContinueWaiting for verification...Cleaning up challenges 12## 检测记录生效$ dig -t txt _acme-challenge.newyingyong.cn @8.8.8.8 更新查看当前服务器所配置的证书 1certbot-auto certificates 使用申请的普通证书，使用certbot-auto renew 使用通配符证书。 添加DNS记录 1git clone https://github.com/ywdblog/certbot-letencrypt-wildcardcertificates-alydns-au.git 1./certbot-auto renew --cert-name simplehttps.com --manual-auth-hook /脚本目录/au.sh 自动更新 11 1 */1 * * root certbot-auto renew --manual --preferred-challenges dns --manual-auth-hook /脚本目录/sslupdate.sh 参考 https://www.jianshu.com/p/c5c9d071e395 https://www.jianshu.com/p/074e147b68b0 certbot工具","tags":[{"name":"web","slug":"web","permalink":"http://wumuwumu.github.io/tags/web/"}]},{"title":"css动画","date":"2018-12-04T13:36:49.000Z","path":"2018/12/04/css动画/","text":"transition transition-duration transition-property transition-delay transition-timing-function animation @keyframes animation animation-name animation-duration animation-timing-function animation-delay animation-iteration-count animation-fill-mode animation-direction animation-play-state(这个要写在最下面，不然不会生效) transform none translate(x,y)/translate3d(x,y,z) translateX(x)/translateY(y)/translateZ(z) materix/materix3d scale/scale3d scaleX/scaleY/scaleZ rotate/rotate3d rotateX/rotateY/rotateZ skew/skewX/skewY perspective","tags":[{"name":"css","slug":"css","permalink":"http://wumuwumu.github.io/tags/css/"}]},{"title":"清除inline-block之间的间隙","date":"2018-12-03T11:54:08.000Z","path":"2018/12/03/清除inline-block之间的间隙/","text":"原因两个inline-block之间存在间隙，这是因为html元素换行导致的（换行和元素之间的空格、tabs、多个空格，结果一样，最后都是一个空格） 移除空格如果我们使用html minimize工具，会清除html之间的空格。如果没有使用就需要我们手动去除。该方法简单但是不推荐使用，阅读不方便。 123456789101112131415&lt;!-- 方法一 --&gt;&lt;div&gt;one&lt;/div&gt;&lt;div&gt;two&lt;/div&gt;&lt;div&gt;three&lt;/div&gt;&lt;!-- 方法二 --&gt;&lt;div&gt;one&lt;/div&gt;&lt;div&gt;two&lt;/div&gt;&lt;div&gt;three&lt;/div&gt;&lt;!-- 方法三 --&gt;&lt;div&gt;one&lt;/div&gt;&lt;!----&gt;&lt;div&gt;two&lt;/div&gt;&lt;!----&gt;&lt;div&gt;three&lt;/div&gt; 负值margin不推荐使用，每个浏览器之间的间隙不同。 1234nav a &#123; display: inline-block; margin-right: -4px;&#125; 父元素font-size设置为0123456.space &#123; font-size: 0;&#125;.space a &#123; font-size: 12px;&#125; 这种方法是推荐使用的，但是在ie和Chrome浏览器(新的浏览器没有问题)上可能出现问题，因为在chrome上有最小字体限制。改进方法如下。 1234.space &#123; font-size: 0; -webkit-text-size-adjust:none;&#125; 使用letter-spacingletter-spacing用于修改字符间的间隙。 123456.space &#123; letter-spacing: -3px;&#125;.space a &#123; letter-spacing: 0;&#125; 使用word-spacingword-spacing修改单词之间的间隙 123456.space &#123; word-spacing: -6px;&#125;.space a &#123; word-spacing: 0;&#125; 使用浮动123a&#123; float:left;&#125; 参考 https://www.zhangxinxu.com/wordpress/2012/04/inline-block-space-remove-%E5%8E%BB%E9%99%A4%E9%97%B4%E8%B7%9D/ 代码 https://codepen.io/wumuwumu/pen/WYmKYX","tags":[{"name":"js","slug":"js","permalink":"http://wumuwumu.github.io/tags/js/"}]},{"title":"Hello World","date":"2018-11-30T07:33:28.000Z","path":"2018/11/30/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]